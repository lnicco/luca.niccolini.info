tiny
thebibliography
Hybrid
web
servers
for
energy
proportional
datacenters
Luca
Niccolini
em
University
of
Pisa
em
luca
niccolini
for
unipi
it
Gianluca
Iannaccone
This
work
was
done
when
Gianluca
Iannaccone
and
Luca
Niccolini
were
at
Intel
Labs
Berkeley
em
Red
Bow
Labs
em
gianluca
redbowlabs
com
Giuseppe
Iannaccone
em
University
of
Pisa
em
giuseppe
iannaccone
unipi
it
We
propose
hybrid
multiprocessor
architecture
for
energy
proportional
web
servers
and
datacenters
to
achieve
significant
energy
savings
at
the
price
of
small
increase
in
service
delay
The
server
consists
of
subsystem
with
low
power
cores
always
on
and
serving
user
requests
when
load
is
low
and
high
performance
subsystem
by
default
in
sleep
mode
woken
up
only
when
the
load
is
high
Through
experiments
on
hardware
prototype
and
an
accurate
timing
and
power
model
of
the
server
we
assess
performance
and
achievable
energy
benefits
and
explore
design
guidelines
for
future
energy
proportional
systems
The
scheduling
mechanism
assigns
incoming
requests
to
low
power
cores
if
the
load
is
below
given
threshold
otherwise
to
high
performance
cores
Through
experiments
on
hardware
prototype
and
an
accurate
timing
and
power
model
of
the
server
we
show
that
energy
proportionality
is
achieved
leading
to
power
savings
between
and
for
typical
workloads
Hardware
architectures
conceived
for
mobile
computing
are
now
powerful
enough
for
their
adoption
in
datacenters
Thanks
to
more
power
aware
design
and
to
more
careful
features
selection
their
performance
are
increasing
while
preserving
high
energy
efficiency
However
such
architectures
are
not
viable
solution
for
all
the
challenges
datacenter
operators
face
Per
workload
fine
tuning
and
accurate
benchmarking
are
required
before
switching
to
low
power
architectures
and
in
some
cases
the
desired
performance
level
cannot
be
reached
We
explore
the
advantages
of
heterogeneous
multi
core
architectures
in
which
high
end
and
low
end
processors
coexist
on
the
same
platform
We
analyze
set
of
web
workloads
on
real
world
prototype
and
show
how
to
respect
SLAs
while
opening
space
for
significant
energy
savings
Categories
and
Subject
Descriptors
Processor
Architectures
Heterogeneous
hybrid
systems
General
terms
Design
Experimentation
Measurement
Performance
Modeling
Keywords
Power
Management
Servers
Asymmetric
Multicore
Introduction
more
efficient
use
of
energy
is
key
challenge
for
modern
datacenter
design
it
would
enable
significant
reduction
of
costs
and
increase
of
computing
power
density
per
unit
volume
Datacenters
building
blocks
are
commodity
servers
providing
ease
of
deployment
low
costs
and
familiar
programming
environments
However
current
servers
and
therefore
datacenters
are
not
energy
efficient
specifically
at
low
load
Barroso
report
that
more
than
of
energy
is
consumed
to
keep
servers
online
while
not
executing
any
useful
work
and
each
server
is
typically
used
below
of
its
peak
performance
Hence
the
call
for
energy
proportional
systems
defined
as
systems
whose
power
consumption
is
proportional
to
the
computing
load
To
reap
the
full
benefits
provided
by
continuous
progress
in
semiconductor
and
storage
technology
in
terms
of
decreasing
cost
per
function
energy
proportional
systems
are
needed
defined
as
systems
whose
power
consumption
is
proportional
to
computing
load
In
this
paper
we
show
that
hybrid
server
architecture
is
promising
option
for
achieving
energy
proportionality
at
small
additional
cost
hybrid
multi
core
architecture
consists
of
mix
of
low
power
cores
and
high
performance
cores
that
coexist
on
the
same
motherboard
and
are
coordinated
by
the
operating
system
or
by
the
application
Low
power
and
high
performance
cores
are
classified
respectively
as
small
and
big
cores
since
advanced
features
such
as
large
caches
out
of
order
execution
etc
affect
core
area
by
requiring
larger
number
of
transistors
The
basic
concept
is
extremely
simple
small
cores
are
always
on
keeping
the
system
responsive
and
serving
user
requests
when
the
load
is
low
Big
cores
are
by
default
in
deep
stand
by
mode
and
are
woken
up
only
when
the
load
is
high
This
approach
is
able
to
exploits
several
trends
in
semiconductor
and
processor
technology
First
with
the
introduction
of
the
Atom
processor
small
core
in
our
terminology
there
is
now
low
power
alternative
to
the
traditional
server
processor
Xeon
product
line
that
shares
the
same
instruction
set
architecture
ISA
Sharing
the
same
ISA
allows
for
providing
single
and
familiar
programming
environment
to
developers
hybrid
system
is
therefore
equivalent
to
traditional
server
and
requires
no
changes
to
the
datacenter
architecture
or
the
management
processes
of
datacenter
operators
Second
the
performance
of
small
cores
is
continuously
increasing
to
meet
users
expectation
of
full
Internet
experience
on
smartphones
netbooks
and
tablets
Most
importantly
battery
life
and
small
form
factor
requirements
force
designers
to
select
and
implement
energy
efficient
features
and
mechanisms
for
improving
performance
per
Watt
voltage
and
frequency
scaling
deep
sleep
states
etc
Finally
high
performance
cores
are
adopting
power
saving
features
clock
gating
power
gating
etc
that
permit
to
turn
off
individual
cores
and
other
subsystems
within
the
same
server
to
maximize
energy
efficiency
at
low
load
In
this
way
an
hybrid
platform
can
exploit
several
important
trends
in
semiconductor
and
computing
technology
Performance
of
small
cores
is
continuously
increasing
to
meet
users
expectation
of
full
Internet
experience
on
smartphones
netbooks
and
tablets
Already
now
low
power
cores
are
powerful
enough
to
run
some
specific
online
web
services
Most
importantly
battery
life
and
small
volume
requirements
forced
designers
to
select
and
implement
energy
efficient
features
and
mechanisms
for
improving
performance
per
Watt
DVFS
States
frequency
throttling
CITATION
NEEDED
ii
High
performance
cores
are
adopting
power
saving
features
effective
at
low
load
or
in
idle
and
stand
by
modes
CITATION
NEEDED
iii
Semiconductor
technology
is
continuing
on
the
downscaling
path
known
as
Moore's
law
leading
to
decrease
of
feature
sizes
and
of
energy
dissipation
per
operation
at
each
new
CMOS
technology
generation
Our
proposal
fully
exploits
this
trend
as
the
relative
energy
efficiency
of
small
and
big
cores
is
preserved
CITATION
NEEDED
The
idea
of
hybrid
or
heterogeneous
architectures
is
not
new
At
the
datacenter
level
several
proposal
have
been
put
forward
in
the
literature
to
include
arrays
of
low
power
systems
next
to
high
performance
ones
that
could
handle
low
load
scenarios
or
specific
intensive
workloads
These
proposals
however
require
to
change
the
way
datacenters
are
designed
and
maintained
and
have
seen
little
adoption
by
datacenters
operators
Further
developers
need
to
refactor
their
code
to
accomodate
for
the
two
different
architectures
that
present
very
different
memory
and
bandwidth
constraints
Hybrid
systems
that
share
the
same
memory
banks
and
subsystems
enable
the
same
codebase
to
achieve
high
single
thread
performance
when
required
and
otherwise
keep
power
consumption
low
At
the
system
or
processor
level
asymmetric
multicore
processors
AMPs
have
been
proposed
as
natural
successors
of
chip
multi
processors
CMPs
since
they
can
provide
energy
efficiency
in
the
execution
of
parallel
threads
due
to
large
number
of
small
cores
while
improving
performance
of
sequential
phases
through
big
cores
large
body
of
work
in
this
field
addresses
the
problem
at
the
single
chip
level
through
theoretical
analysis
and
simulations
using
synthetic
workloads
In
this
paper
we
base
our
analysis
on
real
prototype
akin
to
the
one
used
by
Reddy
Access
to
working
system
allows
for
actual
experimentation
with
real
workloads
as
opposed
to
previous
works
that
use
FPGA
synthesized
CPUs
or
symmetric
multiprocessors
SMP
architectures
with
cores
tuned
to
work
at
different
frequencies
Recent
papers
from
Academia
and
Industry
investigate
the
benefits
of
server
systems
built
exclusively
with
low
power
low
performance
components
considering
different
levels
of
integration
cluster
single
server
and
processor
microarchitecture
These
approaches
aim
to
improve
energy
efficiency
in
order
to
reduce
total
cost
of
ownership
of
datacenters
and
propose
solutions
for
greener
Internet
The
so
called
Wimpy
architectures
are
large
arrays
of
small
low
power
systems
They
are
built
out
of
highly
balanced
components
in
which
the
performance
gap
between
CPU
and
memory
and
subsystems
is
smaller
compared
to
common
server
platforms
They
have
been
successfully
used
to
efficiently
run
bound
memory
bound
and
highly
parallel
workloads
However
some
authors
argued
that
splitting
the
jobs
in
large
number
of
smaller
elaboration
units
might
lead
to
excessive
communication
overhead
High
single
thread
performance
come
at
hefty
power
cost
The
trend
so
far
has
been
to
sacrifice
single
thread
performance
to
keep
power
consumption
down
Both
Academia
and
Industry
are
exploring
arrays
of
low
power
low
performance
components
at
different
levels
of
integration
cluster
single
server
and
processor
microarchitecture
It
has
been
recently
pointed
out
that
despite
large
periods
of
low
utilization
servers
are
rarely
completely
idle
and
in
the
case
of
latency
sensitive
workloads
active
low
power
states
are
the
only
solution
to
reasonably
scale
down
energy
consumption
with
server
load
Therefore
we
believe
that
hybrid
architectures
comprising
small
cores
with
big
ones
can
provide
energy
benefits
at
the
single
server
level
by
maintaining
availability
through
small
cores
and
waking
up
big
cores
when
the
load
increases
so
that
service
level
agreement
SLA
is
not
degraded
The
key
concept
has
been
presented
in
previous
position
paper
here
we
present
complete
analysis
showing
experimental
results
on
prototype
hardware
with
realistic
workloads
Using
the
prototype
we
derive
and
validate
simple
yet
accurate
model
of
the
service
delay
and
power
on
the
hybrid
system
We
then
use
that
model
to
assess
the
feasibility
of
the
hybrid
approach
as
well
as
explore
the
design
space
Specifically
we
study
the
design
space
along
two
dimensions
the
ratio
of
small
vs
big
cores
in
the
system
and
the
relative
performance
of
small
core
vs
big
cores
when
processing
web
requests
We
show
that
the
current
small
core
performance
levels
make
hybrid
multicore
design
feasible
and
that
hybrid
designs
are
an
extremely
promising
solution
to
achieve
energy
proportionality
The
rest
of
the
paper
is
structured
as
follows
In
the
next
section
we
describe
the
prototype
system
and
present
experimental
results
with
different
types
of
webserver
workloads
The
prototype
is
not
optimized
for
energy
efficiency
but
is
fully
adequate
to
evaluate
the
feasibility
of
our
proposal
the
effectiveness
of
the
scheduling
algorithm
in
terms
of
server
performance
server
delay
and
latency
Then
in
Section
we
develop
high
level
model
of
the
hybrid
server
architecture
capable
of
accurately
simulating
timing
performance
and
time
dependent
power
consumption
Such
model
is
validated
in
terms
of
accuracy
in
the
estimation
of
distributions
of
service
delay
times
through
comparison
with
experiments
on
the
hardware
prototype
The
model
is
very
flexible
and
allows
thorough
exploration
of
the
design
space
in
terms
of
the
small
to
big
cores
ratio
and
of
their
relative
performance
The
model
and
its
validation
are
described
in
Section
In
Section
we
use
the
latency
and
power
model
to
explore
various
design
options
and
estimate
the
energy
savings
that
can
be
achieved
Finally
we
draw
our
conclusion
in
section
The
portable
and
mobile
device
market
has
experienced
fast
growth
in
the
last
decade
leading
processor
manufacturers
to
design
small
energy
efficient
general
purpose
CPUs
Mobile
platforms
performances
are
increasing
at
constant
pace
in
order
to
satisfy
user's
expectation
for
full
Internet
experience
on
smartphones
netbooks
and
tablets
Low
energy
and
small
size
requirements
forced
processor
manufacturers
to
start
radically
new
designs
such
as
the
Intel
Atom
AMD
Geode
Via
Nano
and
the
ARM
Cortex
family
These
designs
only
implement
the
most
energy
efficient
features
and
use
smart
mechanisms
to
improve
performance
per
Watt
In
the
server
market
instead
performance
is
still
the
primary
goal
with
high
end
CPUs
reaching
TDP
as
high
as
Also
the
increase
in
processor
performance
is
worsening
the
existing
gap
between
CPU
speed
and
access
latency
to
memory
and
This
leads
to
unbalanced
systems
that
perform
below
the
expectations
for
wide
range
of
workloads
Such
considerations
are
leading
both
Academia

and
Industry
to
investigate
the
benefits
of
server
systems
built
out
of
low
power
low
performance
components
The
problem
is
approached
at
different
integration
scales
cluster
single
server
and
processor
microarchitecture
cite
Gupta
Nathuji
HotPower
but
the
common
goal
of
these
approaches
is
improving
energy
efficiency
in
order
to
lower
datacenters
TCO
and
push
solutions
for
greener
Internet
So
called
Wimpy
architectures
are
more
balanced
than
traditional
commodity
servers
when
considering
the
relative
performance
between
CPU
and
other
subsystems
They
have
been
successfully
used
to
build
large
clusters
that
run
efficiently
bound
memory
bound
and
highly
parallel
workloads
cite
sort
on
Atom
Rivoire
However
datacenters
operators
are
raising
concerns
about
the
increase
in
communication
overhead
response
time
and
error
rate
due
to
the
jobs
being
split
in
an
increasing
number
of
smaller
elaboration
units
In
this
paper
the
problem
is
approached
on
the
single
server
level
by
exploring
the
behavior
of
hybrid
systems
in
which
mobile
small
and
server
big
CPUs
are
mounted
on
the
same
motherboard
and
coordinated
by
the
operating
system
or
by
the
application
We
investigate
how
applications
can
take
advantage
of
the
underlying
heterogeneous
architecture
and
show
how
to
respect
SLAs
by
scheduling
tasks
between
small
and
big
cores
depending
on
the
instantaneous
system
load
introducing
low
power
architectures
Introducing
mobile
processors
Atom
ARM
Cortex
AMD
Geode
Low
power
archs
are
efficiently
used
for
bound
workloads
Explain
why
There
is
an
ever
increasing
gap
between
CPU
performance
and
Memory
and
performance
in
terms
of
speed
high
performance
CPUs
cycles
are
wasted
when
running
Memory
bound
and
bound
workloads
the
still
very
high
idle
power
of
server
systems
is
wasted
for
stalls
Servers
need
high
parallelism
when
serving
high
number
of
concurrent
requests
and
low
power
architectures
can
efficiently
run
high
number
of
independent
threads
the
case
for
web
servers
on
low
power
archs
ARM
based
web
servers
Huge
Array
of
Atom
cores
Seamicro
SM
Mobile
processors
featuring
simultaneous
multithreading
and
virtualization
support
are
now
available
on
the
market
Why
low
power
architectures
are
not
suitable
for
all
kinds
of
workload
Mobile
platforms
are
successfully
used
for
specific
subset
of
datacenter
applications
but
they
are
not
general
enough
for
modern
datacenter
needs
Modern
Datacenters
needs
to
be
flexible
and
programmable
large
sets
of
mobile
platforms
are
well
suited
for
application
that
can
be
split
in
high
number
of
short
parallel
tasks
we
believe
that
server
systems
need
to
be
general
enough
to
An
energy
case
for
hybrid
datacenters
Hybrid
Server
Prototype
We
begin
our
analysis
by
measuring
the
performance
of
hybrid
architecture
research
prototype
In
the
following
subsections
we
describe
the
hardware
and
software
configuration
and
discuss
experimental
results
Prototype
architecture
The
hybrid
server
prototype
is
based
on
standard
dual
socket
motherboard
suited
for
Intel
Xeon
Harpertown
and
compatible
CPUs
however
the
first
socket
hosts
an
Intel
Atom
processor
mounted
by
means
of
an
adaptation
board
The
board
maps
Atom
pins
to
the
Xeon
socket
and
adjusts
voltages
accordingly
Figure
shows
high
level
view
of
the
system
with
the
two
CPUs
connected
to
the
northbridge
chipset
MCH
through
shared
front
side
bus
FSB
MCH
manages
access
to
shared
memory
and
to
peripherals
through
the
controller
IOCH
Table
summarizes
the
main
differences
between
the
two
CPUs
Since
the
original
purpose
of
the
prototype
was
demonstrating
hybrid
server
feasibility
some
tweaks
have
been
made
to
achieve
interoperability
at
the
expense
of
overall
performance
degrading
some
Xeon
features
to
those
supported
by
Atom
For
example
Xeon
clock
and
bus
frequencies
have
been
reduced
to
make
the
FSB
work
at
the
maximum
sustainable
frequency
of
the
Atom
MHz
For
this
reason
the
big
CPU
Xeon
is
constrained
to
GHz
operating
frequency
much
lower
than
the
GHz
maximum
clock
rate
Cache
coherency
is
achieved
by
making
the
smaller
cache
ignore
snoops
for
entries
that
exceed
its
size
Atom
and
Xeon
processors
have
different
microarchitectures
but
implement
partially
overlapping
Instruction
Set
Architectures
ISAs
They
both
have
full
compatibility
exhibiting
some
differences
only
in
instruction
set
extensions
However
operating
system
support
is
needed
to
let
the
applications
abstract
from
these
asymmetries
The
server
runs
the
HeterOS
operating
system
that
is
bit
compliant
OS
providing
the
following
improvements
on
top
of
Linux
Migration
on
fault
an
application
can
execute
instructions
known
only
to
subset
of
cores
The
operating
system
handles
unknown
instruction
exceptions
and
migrates
the
process
that
caused
the
fault
to
core
that
understands
the
instruction
Dynamic
scheduling
HeterOS
provides
both
slow
cores
first
and
fast
cores
first
scheduling
policies
They
dynamically
reschedule
tasks
based
on
performance
metrics
to
take
advantage
of
CPU
bound
and
bound
phases
The
former
scheduler
allocates
processes
to
the
slowest
cores
by
default
and
chooses
when
to
move
task
to
faster
core
depending
on
performance
metrics
collected
on
line
such
as
cycles
per
instruction
and
number
of
stalls
The
fast
cores
first
scheduler
instead
chooses
big
cores
by
default
As
already
mentioned
the
hybrid
server
prototype
is
not
optimized
for
power
consumption
and
therefore
exhibits
high
power
consumption
when
only
the
Atom
is
active
The
main
reason
for
that
is
the
legacy
shared
bus
architecture
where
the
bus
is
always
on
and
MCH
and
IOCH
do
not
have
sleep
states
Measured
wall
power
is
at
idle
and
at
maximum
load
For
this
reason
we
will
use
experiments
to
verify
the
feasibility
of
our
proposal
and
to
validate
our
model
for
hybrid
server
Then
we
will
use
the
model
to
explore
the
performance
achievable
if
power
saving
features
were
fully
implemented
Software
configuration
Here
we
describe
the
software
setup
used
to
assess
the
performance
of
our
hybrid
architecture
prototype
serving
HTTP
requests
The
workbench
consists
of
request
generator
connected
to
the
server
through
Gbps
Ethernet
link
Request
generator
The
client
machine
runs
multiple
instances
of
the
http
load
request
generator
in
order
to
increase
the
request
rate
up
to
the
maximum
load
sustainable
by
the
server
By
using
this
tool
requests
can
be
generated
at
constant
rate
or
with
specified
degree
of
parallelism
The
client
machine
also
measures
per
request
latency
by
computing
it
as
the
interval
between
the
connection
instantiation
at
the
server
and
the
time
the
response
is
received
by
the
client
Web
server
The
software
stack
on
the
server
machine
is
based
on
the
Lighttpd
web
server
and
its
FastCGI
module
Lighttpd
is
lightweight
and
modular
web
server
while
FastCGI
is
typical
solution
for
boosting
the
execution
of
dynamic
requests
It
defines
communication
protocol
between
the
web
server
worker
threads
and
external
processes
using
sockets
as
the
communication
channel
FastCGI
processes
are
created
at
web
server
startup
and
can
run
on
the
server
machine
as
well
as
remotely
In
the
FastCGI
working
model
processes
are
persistent
and
serve
more
than
one
request
saving
the
time
needed
in
legacy
CGI
systems
to
fork
one
process
per
request
Here
we
specifically
use
the
php
cgi
implementation
to
let
the
server
execute
PHP
scripts
citation
needed
Processes
are
distributed
in
way
that
let
us
exploit
multicore
parallelism
Lighttpd
runs
one
worker
thread
on
the
first
Atom
core
while
FastCGI
processes
run
on
both
Xeon
and
Atom
The
worker
thread
is
responsible
for
accepting
all
the
incoming
requests
and
scheduling
them
on
the
most
suitable
FastCGI
process
We
want
requests
to
be
allocated
to
core
and
to
run
on
it
until
completion
without
incurring
in
rescheduling
overhead
Scheduler
In
our
solution
processes
are
statically
assigned
to
cores
with
one
to
one
mapping
We
modified
the
FastCGI
module
to
make
it
aware
of
the
underlying
asymmetric
processor
set
and
changed
the
default
load
balancing
algorithm
into
threshold
based
scheduler
The
scheduler
allocates
incoming
requests
to
small
cores
when
the
load
as
measured
by
the
number
of
concurrent
requests
is
below
defined
threshold
and
to
big
cores
when
the
threshold
is
reached
The
threshold
can
be
larger
than
the
number
of
cores
in
that
case
pending
requests
are
queued
and
their
execution
is
deferred
The
threshold
effectively
is
knob
to
trade
off
power
consumption
for
latency
since
increasing
reduces
the
duty
cycle
of
large
cores
With
this
simple
mechanism
we
create
opportunities
for
big
cores
to
go
in
their
deepest
sleep
state
whenever
the
server
is
underutilized
In
section
we
analyze
the
effectiveness
of
this
mechanism
in
terms
of
energy
efficiency
Dataset
We
collected
GByte
dataset
from
the
English
version
of
Wikipedia
Our
dataset
is
composed
by
files
with
sizes
ranging
from
KB
to
MB
This
is
representative
dataset
for
web
applications
that
work
with
plain
HTML
files
File
size
in
the
dataset
follows
Zipf
distribution
as
in
Workload
The
definition
of
workload
that
is
both
simple
and
representative
of
the
applications
of
today's
datacenters
is
not
straightforward
Servers
in
virtualized
environments
and
MapReduce
nodes
must
be
as
general
purpose
as
possible
Instead
in
the
infrastructure
of
large
websites
most
servers
act
as
specialized
back
end
nodes
running
only
one
kind
of
requests
on
their
fragment
of
the
whole
dataset
memcached
nodes
message
search
We
consider
the
following
workloads
to
be
executed
on
files
in
our
dataset
readfile
statically
serve
the
file
as
is
ksort
sort
key
value
pairs
based
on
key
values
compress
deflate
the
input
file
using
gzip
count
computes
histogram
of
bytes
The
server
retrieves
files
from
disk
split
them
in
chunks
if
needed
apply
transformation
to
file
contents
and
sends
results
back
to
the
client
in
an
HTTP
response
The
workloads
above
allow
us
to
explore
different
deployment
scenarios
The
readfile
workload
represents
the
traditional
web
server
the
other
three
instead
require
to
process
and
perform
computation
on
the
input
data
before
sending
the
response
to
the
client
The
computations
vary
in
complexity
and
the
subsystems
CPU
memory
they
employ
The
workloads
are
conceptually
simple
and
do
not
represent
applications
in
which
slow
blocking
database
requests
are
made
However
they
are
representative
for
servers
managing
high
number
of
concurrent
connections
with
low
latency
Exploring
more
complex
workloads
is
major
part
of
our
future
work
Experimental
results
In
order
to
assess
the
latency
implications
in
systems
with
an
hybrid
set
of
processors
we
stress
the
server
by
gradually
increasing
the
input
query
rate
up
to
the
maximum
sustainable
load
In
the
interest
of
space
we
only
report
results
for
the
count
workload
Results
for
other
workloads
exhibits
very
similar
behavior
Figure
reports
the
system
performance
in
terms
of
service
delay
It
shows
values
for
the
average
service
delay
left
and
the
th
percentile
of
the
service
delay
right
Each
curve
represents
different
value
for
the
scheduling
threshold
the
maximum
number
of
simultaneous
requests
served
by
small
cores
By
setting
we
force
the
system
to
use
big
cores
only
As
can
be
seen
they
sustain
up
to
of
the
maximum
load
of
the
hybrid
solution
All
the
other
curves
have
peak
around
of
the
maximum
load
where
requests
are
being
processed
almost
exclusively
by
low
performance
cores
When
the
load
increases
further
requests
are
forwarded
to
big
cores
and
performance
improves
until
saturation
of
the
whole
system
is
reached
From
Figure
we
evince
speedup
for
our
Xeon
processor
compared
to
Atom
Even
if
both
processors
operate
at
the
same
clock
frequency
the
Atom
cores
are
much
slower
as
they
do
not
implement
all
performance
optimizations
of
Xeon
core
such
as
out
of
order
processing
aggressive
speculation
and
instruction
transformation
Looking
at
the
th
percentile
we
notice
only
to
service
delay
improvement
in
the
high
load
zone
since
our
scheduler
keeps
allocating
requests
also
to
small
cores
in
order
to
maximize
total
throughput
Given
that
in
hybrid
systems
the
SLA
is
determined
by
the
slowest
elaboration
unit
there
is
no
benefit
in
using
small
and
big
cores
alternatively
am
not
sure
understand
this
paragraph
Is
it
needed
would
remove
or
clarify
Latency
and
power
model
In
this
section
we
present
high
level
model
for
timing
and
power
consumption
of
hybrid
server
The
model
is
validated
with
experiments
on
the
prototype
and
then
used
to
assess
achievable
energy
savings
and
performance
Response
Latency
The
hybrid
architecture
we
consider
is
system
with
two
distinct
types
of
elaboration
units
small
CPU
with
low
power
cores
and
big
CPU
with
high
performance
cores
let's
call
them
small
CPUs
and
large
CPUs
which
share
single
infrastructure
scheduler
is
responsible
for
the
allocation
of
incoming
requests
between
processors
it
selects
CPU
for
each
incoming
request
For
the
sake
of
simplicity
in
this
description
we
only
consider
small
CPU
and
large
CPU
CPU
can
run
concurrent
execution
threads
see
Table
When
it
is
fully
loaded
if
incoming
requests
are
queued
and
will
start
being
served
as
soon
as
one
of
the
execution
units
becomes
available
The
total
service
delay
request
experiences
is
then
the
sum
of
two
contributions
queuing
delay
and
execution
delay
For
each
CPU
we
only
model
execution
delay
since
queuing
delay
directly
depends
on
requests
execution
speed
and
on
the
arrival
process
For
given
workload
type
service
time
is
function
of
the
size
of
the
requested
file
of
the
processor
selected
by
the
scheduler
and
of
the
number
of
currently
active
requests
The
file
size
determines
the
number
of
instructions
to
run
while
the
instantaneous
processor
load
is
an
index
for
the
inter
process
interference
due
to
competition
for
shared
resources
Let
be
the
time
request
starts
being
served
and
the
CPU
that
serves
the
request
The
service
delay
is
computed
as
models
the
time
needed
to
accept
request
before
starting
the
execution
and
depends
only
on
the
type
of
processor
accounts
for
the
performance
of
processor
at
given
load
and
is
workload
dependent
coefficient
Given
the
restricted
range
of
file
sizes
in
the
dataset
we
express
the
dependency
on
file
size
as
power
function
with
exponent
Power
Usage
It
has
been
shown
that
the
CPU
is
the
most
energy
proportional
component
in
server
system
thanks
to
idle
sleep
states
with
short
transition
times
and
active
sleep
states
that
trade
execution
speed
for
energy
Other
components
such
as
memory
disks
and
high
speed
buses
either
do
not
implement
sleep
states
or
are
rarely
completely
idle
even
if
underutilized
The
trend
in
server
architectures
however
is
promising
due
to
the
progressive
integration
of
memory
and
controllers
on
the
processor
die
Intel
Sandy
Bridge
This
can
affect
power
consumption
in
two
ways
First
the
shared
bus
is
replaced
by
point
to
point
links
QuickPath
Interconnect
QPI
that
allow
for
more
fine
grained
power
control
Second
the
hardware
logic
dedicated
to
interfacing
with
memory
and
peripherals
directly
depends
on
the
CPU
power
state
and
can
quickly
transition
to
and
from
deep
sleep
states
Without
loss
of
generality
for
the
purpose
of
evaluating
power
consumption
we
can
divide
the
whole
system
in
subsystems
each
associated
to
given
CPU
The
total
power
consumption
can
be
written
as
where
is
the
power
consumption
of
subsystem
associated
to
CPU
Each
subsystem
can
be
in
three
different
energy
states
active
sleep
and
transition
depending
on
the
state
of
the
corresponding
CPU
Let
us
consider
the
subsystem
associated
to
CPU
its
instantaneous
power
consumption
is
function
of
the
state
is
the
power
consumption
when
the
CPU
is
in
the
sleep
state
During
transition
between
active
and
sleep
state
power
consumption
is
approximated
by
power
dissipation
when
the
CPU
is
idle
Finally
when
CPU
is
active
power
is
proportional
to
processor
load
where
is
power
consumption
at
utilization
Model
validation
The
model
has
been
implemented
in
an
event
driven
simulator
using
the
simpy
framework
and
has
been
tested
against
experimental
data
Traces
from
experiments
in
section
are
used
as
input
to
the
simulator
in
order
to
replicate
the
request
arrival
pattern
Values
of
the
model
coefficients
have
been
experimentally
measured
using
the
test
bench
presented
in
section
and
instructing
the
request
generator
to
issue
fixed
number
of
simultaneous
requests
For
each
requests
are
immediately
executed
and
no
queuing
occurs
We
generated
random
requests
across
the
whole
dataset
spectrum
and
measured
the
execution
delay
of
each
request
For
each
CPU
and
load
level
we
compute
model
parameters
and
introduced
in
section
using
to
fit
the
experimental
data
In
our
case
we
obtain
good
fit
with
linear
function
for
Figure
shows
the
request
service
delay
average
left
and
th
percentile
right
for
the
count
workload
Lines
with
symbols
represent
experimental
data
simple
lines
simulation
results
As
can
be
seen
despite
its
simplicity
our
model
correctly
replicates
the
behavior
of
the
real
system
with
delay
peak
in
correspondence
of
slow
cores
saturation
and
performance
speedup
as
soon
as
the
scheduler
starts
allocating
requests
to
fast
cores
The
error
introduced
by
the
model
is
within
few
percentage
points
even
for
the
th
percentile
which
is
harder
to
replicate
than
average
We
validate
our
assumption
by
showing
that
the
model
correctly
predicts
the
system
behavior
for
different
values
of
the
scheduler
threshold
The
threshold
indeed
only
affects
queuing
delay
on
small
cores
For
example
when
the
threshold
is
set
to
the
number
of
small
cores
there
are
no
pending
requests
and
queuing
delay
is
null
on
small
cores
Once
again
we
want
to
stress
the
fact
that
high
values
for
th
percentile
are
driven
by
slow
cores
Even
when
fast
cores
are
used
we
notice
only
slight
decrease
this
is
due
to
an
increase
in
the
probability
of
large
requests
being
allocated
to
big
core
Evaluating
hybrid
server
design
Based
on
the
model
described
in
the
previous
section
we
assess
power
consumption
of
hybrid
multicore
architectures
as
function
of
load
and
evaluate
achievable
energy
savings
and
performance
As
mentioned
our
prototype
would
not
be
adequate
to
achieve
energy
saving
because
idle
power
is
too
high
and
Xeon
performance
is
intentionally
suppressed
To
evaluate
achievable
power
consumption
for
an
optimized
board
we
measured
power
consumption
of
an
AtomN
netbook
exhibiting
dynamic
range
as
the
Atom
but
better
idle
power
It
consumes
with
no
load
and
at
maximum
load
Then
we
consider
fully
performing
Xeon
as
large
CPU
with
power
at
peak
of
We
also
assume
that
the
subsystem
associated
to
the
large
CPU
can
be
turned
to
low
power
standby
mode
in
low
load
time
intervals
and
is
awakened
by
the
scheduler
only
when
needed
Reasonably
the
power
consumed
in
sleep
state
can
be
expressed
as
fraction
of
In
the
following
we
consider
two
cases
and
The
first
is
an
ideal
case
and
is
used
coupled
with
zero
transition
time
to
consider
an
ideal
optimistic
situation
whereas
the
second
case
is
very
conservative
and
should
represent
pessimistic
case
Coordinated
sleep
states
among
components
cannot
be
as
fast
as
CPU
sleep
states
states
which
have
transition
latencies
in
the
order
of
microseconds
For
this
reason
we
consider
transition
times
up
to
tens
of
milliseconds
Figure
shows
average
power
consumption
average
request
delay
and
th
percentile
of
delay
in
the
entire
load
range
Results
for
the
count
workload
are
shown
on
the
left
whereas
results
for
the
compress
workload
are
shown
on
the
right
The
scheduling
threshold
is
fixed
to
for
clarity
of
presentation
We
shall
discuss
its
effect
on
power
later
on
The
thick
straight
line
represents
the
worst
case
scenario
system
that
consumes
the
sum
of
idle
power
for
the
two
subsystems
at
idle
and
the
sum
of
peak
power
at
maximum
Different
transition
times
are
considered
corresponding
to
ms
Note
how
all
the
solutions
presented
exhibit
good
energy
proportionality
compared
to
the
worst
case
thanks
to
the
low
energy
of
the
small
CPU
subsystem
and
to
efficient
sleep
states
of
the
large
CPU
subsystem
When
the
load
increases
above
all
the
power
curves
converge
towards
the
worst
case
scenario
This
is
due
to
the
lack
of
idle
periods
that
the
big
CPU
can
exploit
to
undergo
the
transition
to
sleep
state
The
real
advantage
in
energy
terms
is
due
to
the
fact
that
typical
server
only
spend
small
fraction
of
time
in
high
load
region
and
has
low
load
for
most
of
the
time
In
our
solution
power
dissipation
is
small
at
low
load
when
only
the
small
CPU
subsystem
is
active
This
come
at
the
price
of
increased
latency
in
servicing
requests
as
we
have
shown
in
the
previous
Section
To
better
understand
the
latency
vs
energy
savings
trade
off
we
can
use
our
service
delay
model
of
Section
to
evaluate
several
what
if
scenarios
In
particular
the
model
allows
us
to
explore
the
design
space
across
two
dimensions
the
ratio
of
small
to
big
cores
and
the
relative
performance
of
small
to
big
core
Along
the
first
dimension
as
the
number
of
small
cores
increases
more
requests
will
be
served
by
small
cores
and
the
overall
average
service
delay
will
be
larger
On
the
other
hand
energy
usage
will
be
lower
because
high
power
big
cores
can
be
idle
longer
Figure
shows
the
average
service
delay
and
average
energy
spent
per
request
as
function
of
the
ratio
of
number
of
Atom
cores
to
Xeon
cores
To
derive
this
figure
we
used
as
input
request
load
that
mirrors
the
utilization
distribution
reported
in
for
Google's
datacenters
From
the
figure
designer
can
pick
desired
average
service
latency
or
energy
per
request
and
obtain
the
best
number
of
Atom
cores
to
reach
that
performance
Furthermore
the
model
shows
at
what
point
adding
more
Atom
cores
has
little
impact
on
latency
or
energy
usage
This
is
expected
as
for
those
ratios
all
requests
are
always
served
by
the
Atom
cores
and
the
Xeon
cores
stay
always
idle
The
actual
value
is
workload
dependent
ratio
of
in
our
case
and
datacenter
operators
can
estimate
the
load
of
requests
and
choose
the
best
operating
point
accordingly
The
second
dimension
the
relative
performance
of
cores
allows
us
to
understand
the
impact
of
technology
advances
Given
the
size
and
growth
prospects
of
today's
mobile
and
tablet
markets
significant
development
effort
is
dedicated
to
improve
the
performance
of
small
low
power
cores
Figures
and
plot
the
average
response
delay
and
energy
per
request
as
function
of
the
Atom
speedup
as
we
vary
the
performance
of
the
Atom
cores
while
keeping
the
Xeon
cores
the
same
We
also
scale
power
usage
linearly
with
performance
in
keeping
with
Atom's
design
constraint
for
which
feature
is
implemented
only
if
it
provides
performance
for
power
The
workload
is
the
same
as
before
and
follows
the
utilization
distribution
similar
to
Note
that
we
assume
the
overall
power
usage
to
stay
the
same
in
keeping
with
Moore's
law
and
processor
designs
that
maintain
constant
power
envelope
across
generations
of
processors
We
assume
the
overall
power
usage
to
scale
with
performance
following
the
Atom
design
constraint
for
which
feature
is
implemented
only
if
it
gives
performance
improvement
for
less
than
power
cost
Each
line
in
the
plots
corresponds
to
ratio
of
Atom
vs
Xeon
cores
from
one
to
four
The
figures
show
two
interesting
trends
As
the
Atom
performance
drops
below
of
the
current
performance
there
is
very
little
energy
advantage
in
using
more
Atom
cores
This
is
because
the
processing
time
of
the
Atom
cores
is
so
large
that
more
incoming
requests
need
to
be
handled
by
the
Xeon
As
consequence
Xeon
cores
have
very
few
opportunities
to
transition
to
an
idle
state
At
the
other
side
of
the
spectrum
as
the
performance
of
the
Atom
cores
increases
adding
more
small
cores
has
little
impact
on
the
response
delay
but
helps
in
reducing
energy
per
request
significantly
If
Atom
cores
were
twice
as
fast
as
the
cores
in
our
hybrid
prototype
the
energy
per
request
could
be
almost
halved
incurring
negligible
service
delay
penalty
service
delay
and
especially
its
th
percentile
are
not
strongly
affected
by
the
transition
intervals
This
is
due
to
the
nature
of
our
dataset
that
according
to
very
common
power
law
distribution
has
small
fraction
of
large
files
We
find
that
distribution
tails
for
service
delay
are
determined
by
small
number
of
long
requests
running
on
the
small
CPU
Therefore
if
for
given
workload
the
performance
achievable
with
only
the
small
CPU
subsystem
is
acceptable
then
hybrid
solution
will
not
undermine
such
performance
if
transition
time
is
small
enough
Indeed
analyzing
the
service
delay
results
for
the
compress
workload
we
see
that
ms
transition
time
is
too
large
for
requests
that
on
average
experience
service
delay
between
ms
and
ms
see
Figure
In
Figure
we
use
the
utilization
distribution
from
in
order
to
provide
an
estimate
for
the
average
power
consumed
and
the
average
request
delay
for
different
implementation
options
Figure
shows
the
average
power
for
the
configurations
in
Figure
plus
the
case
with
instantaneous
transition
time
and
scheduling
threshold
equal
to
the
number
of
small
cores
As
can
be
seen
the
affects
power
only
within
few
percentage
points
It
is
then
reasonable
to
set
it
to
the
minimum
value
and
possibly
use
it
for
fine
tuning
of
the
system
whenever
an
additional
latency
can
be
tolerated
The
implementation
of
quick
sleep
modes
is
key
for
an
hybrid
multicore
systems
to
be
more
energy
proportional
Our
results
show
that
achievable
energy
saving
is
more
than
for
instantaneous
transition
times
and
between
to
range
with
transition
times
lower
than
ms
Figure
reports
the
average
delay
and
energy
per
request
for
design
solutions
with
varying
small
to
big
cores
ratio
It
clearly
shows
the
energy
delay
tradeoff
with
high
delay
for
the
only
small
cores
option
and
energy
inefficiency
for
the
only
big
cores
options
Hybrid
architectures
offer
the
flexibility
to
tune
the
system
between
these
two
extreme
alternatives
enabling
one
to
achieve
the
lowest
power
consumption
within
the
server
delay
constraints
Related
Work
In
order
to
investigate
the
OS
mechanisms
needed
to
support
AMPs
and
their
performance
impact
on
applications
hardware
prototypes
have
been
implemented
Emulation
is
provided
through
FPGA
synthesized
CPUs
or
symmetric
multiprocessors
SMP
architectures
with
cores
tuned
to
work
at
different
frequencies
The
authors
of
Ref
instead
use
multi
family
platform
with
different
microarchitecture
CPU
similar
to
our
hardware
prototype
Despite
the
growing
volume
of
work
that
investigates
mechanisms
to
make
the
asymmetry
transparent
to
user
software
authors
of
Ref
state
that
in
some
cases
applications
need
to
be
asymmetry
aware
in
order
to
not
undermine
performance
In
our
work
we
chose
to
use
the
latter
approach
due
to
the
highly
parallel
and
latency
sensitive
nature
of
our
web
application
The
case
for
energy
efficient
hybrid
server
architectures
has
been
presented
in
The
authors
explore
server
design
space
with
different
solutions
for
task
managing
including
migration
and
show
that
efficiency
at
low
load
can
be
improved
while
handling
spikes
in
request
rate
In
and
the
problem
is
approached
at
the
processor
chip
level
showing
that
asymmetric
multicore
processors
can
provide
energy
benefits
on
two
levels
parallel
speedup
and
energy
scaling
The
former
exploit
big
cores
to
speedup
serial
portions
of
task
while
the
latter
uses
high
performance
units
to
run
CPU
intensive
phases
All
this
work
is
based
on
theoretical
analysis
and
simulations
using
synthetic
workloads
separate
class
of
works
study
the
implementation
of
asymmetry
aware
schedulers
in
general
purpose
operating
systems
These
solutions
exploit
heterogeneity
to
dynamically
assign
threads
to
to
fast
or
slow
CPUs
in
order
to
accelerate
or
run
more
efficiently
phases
within
the
same
application
In
our
work
we
deal
with
different
problem
the
application
accepts
incoming
requests
and
serve
them
in
the
more
energy
efficient
way
by
statically
pinning
threads
to
cores
The
application
itself
is
asymmetry
aware
and
OS
support
is
needed
only
to
mask
low
level
architectural
differences
Conclusion
In
this
paper
we
have
addressed
the
problem
of
energy
efficiency
in
datacenters
proposing
solution
based
on
hybrid
multiprocessor
systems
We
have
shown
with
experiments
and
accurate
modeling
that
system
comprising
small
CPU
subsystem
used
at
low
load
and
large
CPU
subsystem
in
sleep
mode
by
default
woken
up
only
in
time
intervals
of
high
load
can
exhibit
energy
proportionality
at
small
cost
in
terms
of
service
delay
Experiments
with
realistic
workload
on
hardware
prototype
have
allowed
us
to
evaluate
system
performance
in
terms
of
service
delay
and
to
demonstrate
scheduler
feasibility
Experiments
also
enabled
us
to
validate
an
accurate
model
of
server
timing
and
power
consumption
that
we
have
used
to
evaluate
performance
and
power
savings
achievable
with
an
optimized
hybrid
server
Acknowledgments
Support
from
INTEL
Research
is
gratefully
acknowledged
Questa
roba
che
viene
dopo
proprio
necessaria
Future
work
include
the
evaluation
of
manycore
architectures
with
few
big
cores
and
high
number
of
small
elaboration
units
We
also
want
to
extend
the
present
analysis
by
running
workloads
with
more
stringent
latency
requirements
Finally
although
in
this
work
we
have
shown
that
even
simple
scheduling
solution
guarantee
significant
savings
the
overall
system
efficiency
can
be
improved
with
load
prediction
algorithm
that
helps
avoiding
unproductive
transition
to
sleep
state
abbrv
thebibliography
Building
power
proportional
router
Luca
Niccolini
Gianluca
Iannaccone
Sylvia
Ratnasamy
Jaideep
Chandrashekar
Luigi
Rizzo
University
of
Pisa
RedBow
Labs
Technicolor
Labs
University
of
California
Berkeley
While
there
have
been
many
recent
proposals
to
improve
the
energy
efficiency
of
various
aspects
of
the
Internet
ecosystem
there
has
been
relatively
little
work
focusing
on
the
network
infrastructure
particularly
the
routing
elements
of
the
network
These
are
inherently
inefficient
because
they
are
often
provisioned
for
peak
load
and
operate
at
far
lower
utilization
levels
and
because
they
exhibit
very
little
variation
in
power
even
at
very
low
load
In
this
paper
using
the
vehicle
of
off
the
shelf
software
routers
platform
that
is
accessible
to
us
We
aim
at
improving
the
power
efficiency
of
network
routers
without
compromising
their
performance
Using
server
based
software
routers
as
our
prototyping
vehicle
we
investigate
the
design
of
router
that
consumes
power
in
proportion
to
the
rate
of
incoming
traffic
We
start
with
an
empirical
study
of
power
consumption
in
current
software
routers
decomposing
the
total
power
consumption
into
its
component
causes
Informed
by
this
analysis
we
develop
software
mechanisms
that
exploit
the
underlying
hardware's
power
management
features
for
more
energy
efficient
packet
processing
We
incorporate
these
mechanisms
into
Click
and
demonstrate
router
that
matches
the
peak
performance
of
the
original
unmodified
router
while
consuming
up
to
half
the
power
at
low
loads
with
negligible
impact
on
the
packet
forwarding
latency
This
paper
addresses
the
power
efficiency
of
core
network
equipment
devising
techniques
to
reduce
consumption
without
compromising
on
performance
Using
the
vehicle
of
server
based
software
routers
we
attempt
to
build
router
that
consumes
power
proportionally
to
the
rate
of
incoming
traffic
We
first
measure
where
power
is
consumed
while
processing
packets
and
then
present
several
software
mechanisms
to
utilize
the
hardware
in
more
energy
efficient
manner
As
part
of
our
work
we
incorporate
these
ideas
into
Click
and
implement
router
that
reaches
the
same
peak
performance
of
the
original
implementation
while
consuming
up
to
half
the
power
at
lower
loads
with
negligible
effect
on
forwarding
latency
While
our
particular
implementation
is
based
on
routers
built
using
general
purpose
parts
the
ideas
we
present
are
of
general
interest
and
are
applicable
to
more
traditional
routing
platforms
based
on
custom
processors
Introduction
The
network
infrastructure
is
often
viewed
as
an
attractive
target
for
energy
efficient
design
since
routers
are
provisioned
for
peak
loads
but
operate
at
low
average
utilization
levels
studies
report
network
utilization
levels
of
in
enterprises
in
large
ISPs
and
variability
in
ADSL
networks
At
the
same
time
network
equipment
is
notoriously
inefficient
at
low
load
survey
of
network
devices
reveals
that
the
power
consumed
when
router
is
not
forwarding
any
packets
is
between
of
its
peak
power
consumed
when
processing
packets
at
full
line
rate
Thus
although
in
theory
networks
offer
significant
opportunity
for
energy
efficiencies
these
savings
are
rarely
realized
in
practice
This
inefficiency
is
increasingly
problematic
as
traffic
volumes
continue
their
rapid
growth
and
has
led
to
growing
attention
in
both
research
and
industry

In
anecdotal
evidence
discussions
with
major
ISP
revealed
that
infrastructure
power
consumption
represents
their
second
largest
monthly
recurring
cost
second
only
to
labor

and
we
see
calls
for
research
on
the
topic
from
router
vendors
Prior
work
on
improving
network
energy
efficiency
has
followed
one
of
two
broad
trajectories
The
first
takes
network
wide
view
of
the
problem
proposing
to
modify
routing
protocols
for
energy
savings
The
general
theme
here
is
to
re
route
packets
so
as
to
consolidate
traffic
onto
fewer
paths
If
such
re
routing
can
offload
traffic
from
router
entirely
then
that
router
may
be
powered
down
or
enter
low
power
sleep
state
The
second
line
of
work
explores
different
strategy
to
avoid
changing
routing
protocols
an
area
fraught
with
concerns
over
stability
and
robustness
these
proposals
instead
advocate
changes
to
the
internals
of
router
The
authors
assume
hardware
support
for
low
power
modes
in
routers
and
develop
algorithms
that
invoke
these
low
power
modes
Their
results
using
simulation
and
theoretical
models
of
router
power
consumption
appear
encouraging
suggesting
energy
savings
of
up
to
for
network
utilizations
of
To
date
however
there
have
been
no
published
reports
on
attempts
to
actually
build
an
energy
efficient
router
Motivated
by
this
deficiency
we
thus
tackle
the
question
of
how
one
might
build
such
an
energy
efficient
router
challenge
in
this
is
that
server
power
management
for
routing
workloads
and
in
fact
streaming
workloads
more
generally
is
largely
uncharted
territory
with
no
published
reports
on
what
tradeoffs
are
achievable
with
existing
power
management
knobs
We
thus
start
with
an
empirical
study
of
power
consumption
in
current
software
routers
decomposing
the
total
power
consumption
to
understand
where
when
and
why
power
is
consumed
Informed
by
these
findings
we
then
evaluate
different
techniques
to
reduce
the
power
usage
of
individual
components
and
understand
their
impact
on
performance
The
traditional
challenge
in
building
an
energy
efficient
system
lies
in
the
inherent
tradeoff
between
energy
consumption
and
various
performance
metrics
in
our
case
forwarding
rate
and
latency
We
cannot
compromise
on
peak
forwarding
rates
since
the
incoming
traffic
rate
is
dictated
by
factors
external
to
given
router
and
since
we
do
not
want
to
modify
routing
protocols
We
can
however
explore
options
that
tradeoff
latency
for
improved
efficiency
The
ability
to
do
so
requires
that
the
underlying
hardware
expose
primitives
for
low
power
operation
and
higher
level
algorithms
that
invoke
these
primitives
to
best
effect
Our
work
focuses
on
developing
these
higher
layer
algorithms
and
we
do
so
in
the
context
of
general
purpose
server
hardware
General
purpose
hardware
typically
offers
system
designers
three
knobs
for
low
power
operation
regulate
the
frequency
and
hence
power
consumption
at
which
individual
CPU
cores
process
work
ii
put
an
idle
core
into
sleep
state
powering
down
sub
components
of
the
idle
core
iii
consolidate
packet
processing
onto
fewer
cores
adjusting
the
number
of
active
cores
As
we
shall
see
not
only
do
each
of
the
above
offer
very
different
performance
vs
power
tradeoffs
they
also
lend
themselves
to
very
different
strategies
in
terms
of
the
power
management
algorithms
we
must
develop
For
example
sleep
mode
savings
are
best
exploited
by
maximizing
idle
times
which
implies
processing
work
as
quickly
as
possible
while
frequency
scaling
is
best
exploited
by
processing
work
as
slowly
as
possible
which
reduces
idle
times
The
question
of
how
to
best
combine
the
above
hardware
options
is
to
our
knowledge
still
an
area
of
active
research
for
most
application
contexts
and
is
entirely
uncharted
territory
for
networking
applications
In
fact
to
our
knowledge
there
have
been
no
studies
on
the
combined
effect
of
all
three
power
management
primitives
for
any
application
context
although
recent
work
considers
two
primitives
at
time
in
the
context
of
database
workloads
we
discuss
related
work
in
greater
detail
in
sec
related
We
thus
start
by
studying
the
energy
savings
enabled
by
different
hardware
options
for
different
traffic
workloads
Building
on
this
understanding
we
develop
unified
power
management
algorithm
that
invokes
different
options
as
appropriate
dynamically
adapting
to
load
for
optimal
savings
We
implement
this
algorithm
in
Click
software
router
and
demonstrate
that
its
power
consumption
scales
in
proportion
to
the
input
traffic
rate
while
introducing
little
latency
overhead
key
goal
of
our
implementation
is
to
avoid
interfering
with
the
router's
peak
forwarding
performance
and
instead
seek
savings
by
exploiting
the
natural
variability
in
traffic
demand
As
such
our
prototype's
performance
and
power
usage
is
unchanged
under
peak
load
but
offers
significant
savings
at
lower
data
rates
For
real
world
traffic
traces
our
prototype
records
reduction
in
power
consumption
with
no
additional
packet
drops
and
only
small
less
than
cost
in
packet
forwarding
latency
To
our
knowledge
this
is
the
first
demonstration
of
an
energy
efficient
router
prototype
Before
proceeding
we
elaborate
on
our
choice
of
general
purpose
hardware
as
prototyping
platform
and
how
this
impacts
the
applicability
of
our
work
To
some
extent
our
choice
is
borne
of
necessity
to
our
knowledge
current
network
hardware
does
not
offer
low
power
modes
of
operation
or
at
least
none
exposed
to
third
party
developers
in
contrast
server
hardware
does
incorporate
such
support
with
standard
software
interfaces
and
support
in
all
major
operating
systems
That
said
current
network
equipment
may
employ
very
different
hardware
options
and
hence
we
expand
more
concretely
on
the
applicability
of
our
work
to
each
Our
work
applies
directly
to
software
routers
built
on
commodity
hardware
an
area
of
growing
interest
in
recent
research
with
commercial
adoption
in
the
lower
end
router
market
Network
appliances
load
balancers
WAN
optimizers
firewalls
IDS
etc
commonly
rely
on
hardware
and
these
form
an
increasingly
important
component
of
the
network
infrastructure
recent
paper
revealed
that
an
enterprise
network
of
routers
deployed
over
appliances
Our
work
is
likewise
directly
applicable
to
such
appliances
Commercial
routers
typically
rely
on
network
processors
NPs
rather
than
general
purpose
ones
While
the
specifics
of
our
results
may
not
apply
directly
to
NPs
we
expect
that
the
overall
methodology
by
which
we
compare
and
combine
different
power
options
will
be
of
relevance
This
is
because
the
power
modes
that
hardware
offers
reflect
fundamental
technology
options
turning
cores
on
off
frequency
and
voltage
scaling
clock
gating
etc
and
hence
it
is
likely
that
NP
designers
will
pursue
similar
approaches

Many
routers
rely
on
specialized
ASICs
particularly
for
simple
low
level
tasks
such
as
checksum
calculations
it
is
unclear
what
form
of
power
modes
ASICs
will
evolve
to
offer
and
hence
we
conservatively
assume
our
work
does
not
apply
to
these
Finally
we
note
growing
trend
towards
equipment
that
augments
the
traditional
ASIC
and
NP
based
platform
with
general
purpose
CPUs
in
the
form
of
beefed
up
control
planes
Arista
Networks
as
one
of
multiple
heterogeneous
data
plane
engines
Cavium
or
as
service
blades
on
the
data
plane
Cisco's
Application
eXtension
Platform
More
generally
we
believe
our
results
can
positively
influence
the
hardware
support
for
power
management
that
emerges
in
specialized
NPs
and
ASICs
by
demonstrating
what
magnitude
of
energy
savings
are
possible
using
basic
hardware
primitives
what
performance
tradeoff
comes
with
these
savings
and
which
of
the
feasible
kinds
of
hardware
primitives
maximize
benefits
Hardware
primitives
equivalent
to
those
found
in
hardware
are
still
in
their
infancy
for
specialized
networking
equipment
Yet
the
necessary
support
will
readily
be
deployed
in
networks
where
it
proves
valuable
with
support
for
sleep
and
rate
selection
for
Ethernet
already
under
development
For
comparison
computer
power
management
compatible
with
the
ACPI
standard
went
from
scarce
to
widely
deployed
in
scant
five
to
ten
years
The
remainder
of
the
paper
is
organized
as
follows
We
start
with
an
overview
of
related
work
and
review
of
the
power
consuption
of
current
software
routers
sec
measurement
and
of
the
power
management
features
modern
server
hardware
offer
sec
background
We
continue
with
techniques
to
reduce
power
by
eliminating
software
inefficiencies
sec
power
and
then
study
the
tradeoffs
between
different
power
management
options
sec
power
tradeoffs
We
present
the
design
and
implementation
of
our
unified
power
management
algorithm
in
sec
implementation
and
the
evaluation
of
our
prototype
in
sec
evaluation
The
remainder
of
the
paper
is
organized
as
follows
We
start
by
understanding
our
baseline
what
is
the
power
consumption
of
current
unmodified
software
routers
and
what
hardware
power
management
features
do
modern
servers
offer
Todays
Internet
infrastructure
comprising
various
kinds
of
computers
data
centers
transmission
equipment
switches
routers
etc
consume
significant
amount
of
energy
In
the
alone
studies
have
conservatively
estimated
that
the
network
infrastructure
alone
may
be
consuming
around
TWh
year
less
conservative
studies
indicate
this
to
be
as
high
as
TWh
year
get
citations
form
sylvia's
NSDI
paper
This
directly
translates
in
sizeable
cost
steadily
growing
for
datacenter
operators
internet
service
providers
and
enterprises
Not
surprisingly
recent
years
have
seen
number
of
proposals
that
describe
ideas
exploring
how
to
improve
energy
efficiencies
in
datacenters
wireless
infrastructure
enterprises
office
and
home
networks
Surprisingly
there
has
been
relatively
work
addressing
the
energy
efficiency
of
the
broader
Internet
network
infrastructure
This
is
an
attractive
target
because
of
its
inherent
inefficiency
networks
are
generally
provisioned
for
peak
load
by
are
typically
operated
at
very
low
utilization
the
ineffciencies
come
from
the
fact
that
routers
consume
fixed
and
substantial
amount
of
power
regardless
of
whether
they
are
forwarding
packets
or
not
With
the
rest
of
the
ecosystem
having
been
put
under
microscope
and
various
proposals
put
forth
to
improve
its
energy
efficiency
the
network
infrastructure
stands
out
In
which
is
the
singular
work
in
this
area
the
authors
how
networks
can
be
made
more
efficient
by
making
power
awareness
an
integral
part
of
the
network
design
and
configuration
In
this
paper
we
look
at
how
to
construct
power
proportional
router
specifically
server
based
Internet
software
routers
While
the
design
principles
we
derive
in
this
paper
are
of
general
applicability
we
use
server
based
routers
as
platform
for
four
reasons
First
they
are
open
programmable
platforms
to
which
we
have
access
Second
the
construction
of
such
router
informs
whether
off
the
shelf
software
based
routers
which
have
recently
been
shown
to
provide
comparable
performance
to
traditional
routers
are
practical
These
proposals
focused
solely
on
peak
performance
with
little
regard
to
energy
efficiency
Building
software
router
that
can
deliver
peak
performance
and
use
the
underlying
hardware
in
the
most
energy
efficient
manner
would
strengthen
the
case
for
server
based
networks
The
corollary
here
is
that
if
software
routers
cannot
be
made
energy
efficient
it
is
unlikely
that
they
will
ever
be
deployed
in
large
scale
networks
Third
current
server
processor
architectures
are
three
to
four
generations
ahead
of
contemporary
dedicated
router
architectures
and
incorporate
number
of
power
management
features
and
knobs
voltage
and
frequency
scaling
multithreading
power
gating
sleep
states
and
so
on
and
our
goal
is
to
understand
how
these
techniques
which
will
eventually
make
their
way
into
traditional
router
architectures
can
be
exploited
for
packet
processing
workloads
And
finally
several
aspects
of
our
implementation
architecture
our
approach
to
partitioning
tasks
across
multiple
cores
are
applicable
to
network
processor
based
routers
Past
work
has
prescribed
models
of
energy
efficient
routers
nsdi
and
speculated
on
hardware
technologies
such
as
DVS
and
xyz
components
that
might
be
used
to
build
an
energy
efficient
router
sigcomm
but
no
attempt
to
actually
build
one
and
no
empirical
evaluation
of
these
ideas
in
the
context
of
existing
hardware
or
software
need
to
fill
in
citations
this
is
Sylvia's
sentence
We
start
by
looking
at
recent
proposal
for
software
router
the
Routebricks
software
stack
and
examine
where
power
is
consumed
and
why
Subsequently
we
evaluate
specific
techniques
load
consolidation
and
per
cycle
energy
efficiency
to
reduce
the
power
consumption
and
then
derive
strategies
to
combine
these
different
techniques
optimally
and
build
prototype
that
implements
these
We
then
evaluate
its
performance
with
respect
to
performance
per
watt
at
low
load
peak
performance
and
latency
and
find
that
our
design
reduce
energy
usage
by
half
under
low
load
without
compromising
the
peak
performance
of
the
original
Routebricks
software
the
packet
processing
latency
is
well
below
even
in
the
worst
case
We
point
out
that
we
are
not
trying
to
reduce
the
peak
power
consumption
of
the
software
router
our
focus
is
on
making
the
software
router
more
power
proportional
Our
prototype
preserves
the
peak
performance
of
the
original
Routebricks
software
while
saving
energy
under
low
load
The
rest
of
the
paper
is
structured
as
follows
The
next
sections
provides
an
overview
of
related
work
in
this
area
and
of
power
management
features
available
in
modern
servers
Section
presents
the
results
of
our
analysis
of
power
consumption
and
identifies
the
relative
contribution
to
power
usage
of
the
various
system
components
In
Section
we
describe
the
software
strategies
to
minimize
power
consumption
while
Section
details
our
implementation
of
the
energy
savings
mechanisms
Section
presents
results
of
our
evaluation
both
on
synthetic
workloads
and
actual
high
speed
packet
traces
Finally
Section
provides
some
concluding
remarks
Then
we
evaluate
the
software
mechanisms
that
are
available
to
manage
power
and
how
they
can
be
used
without
compromising
the
guiding
design
principles
behind
the
Routebricks
software
architecture
Our
goal
is
to
preserve
the
peak
performance
of
the
original
Routebricks
software
while
saving
energy
under
low
load
In
our
quest
for
energy
efficiency
we
follow
two
key
ideas
load
consolidation
how
to
dynamically
adapt
the
number
of
cores
to
load
per
cycle
energy
efficiency
how
to
make
sure
all
available
cycles
in
the
server
are
put
down
to
good
use
We
present
the
design
and
implementation
of
an
energy
efficient
Routebricks
cluster
and
evaluate
its
performance
with
respect
to
performance
per
watt
at
low
load
peak
performance
and
latency
We
find
that
our
design
reduce
energy
usage
by
half
under
low
load
without
compromising
the
peak
performance
of
the
router
We
pay
penalty
in
packet
processing
latency
but
that
penalty
is
well
below
even
in
the
worst
case
Related
Work
We
discuss
relevant
work
in
the
context
of
both
networking
and
computer
systems
Energy
efficiency
in
networks
Prior
work
on
improving
network
energy
efficiency
has
followed
one
of
two
broad
trajectories
The
first
takes
network
wide
view
of
the
problem
proposing
to
modify
routing
protocols
for
energy
savings
The
general
theme
is
to
re
route
packets
so
as
to
consolidate
traffic
onto
fewer
paths
If
such
re
routing
can
offload
traffic
from
router
entirely
then
that
router
may
be
powered
down
entirely
The
second
line
of
work
explores
different
strategy
to
avoid
changing
routing
protocols
an
area
fraught
with
concerns
over
stability
and
robustness
these
proposals
instead
advocate
changes
to
the
internals
of
router
or
switch

The
authors
assume
hardware
support
for
low
power
modes
in
routers
and
develop
algorithms
that
invoke
these
low
power
modes
They
evaluate
their
algorithms
using
simulation
and
abstract
models
of
router
power
consumption
to
date
however
there
has
been
no
empirical
validation
of
these
solutions
Our
focus
on
building
power
proportional
prototype
router
complements
the
above
efforts
For
the
first
line
of
work
power
proportional
router
would
enable
power
savings
even
when
traffic
cannot
be
entirely
offloaded
from
router
To
the
second
we
offer
platform
for
empirical
validation
and
our
empirical
results
in
sec
power
tradeoffs
highlight
the
pitfalls
of
theoretical
models
further
distinction
relative
to
several
of
the
above
solutions
is
that
we
do
not
assume
any
active
traffic
shaping
that
creates
opportunities
for
low
power
operation
and
instead
only
exploit
the
naturally
occurring
variability
in
traffic
Traffic
shaping
would
only
improve
our
results
Power
management
in
user
laptops
and
desktops
has
typically
focused
on
reducing
idle
time
consumption
an
idle
computer
will
typically
put
the
CPU
in
sleep
state
dim
the
screen
spin
down
the
disk
and
eventually
enter
suspend
state
Energy
efficient
systems
With
the
rise
of
data
centers
and
their
emphasis
on
energy
efficiency
support
for
power
management
in
servers
has
matured
over
the
last
decade
Today's
servers
offer
variety
of
hardware
options
for
power
management
along
with
the
corresponding
software
hooks
and
APIs
This
has
led
to
recent
systems
work
exploring
how
to
best
leverage
this
hardware
support
with
the
aim
of
achieving
power
proportionality
while
actively
processing
particular
workload
Many
of
these
efforts
focus
on
cluster
level
solutions
that
dynamically
consolidate
work
on
small
number
of
servers
and
power
down
the
remaining

Such
work
is
orthogonal
to
ours
as
their
techniques
are
not
applicable
to
our
context
Consolidating
work
on
fewer
servers
allows
for
the
remaining
idle
nodes
in
the
cluster
to
be
powered
down
The
end
result
is
better
power
proportionality
at
the
cluster
level
The
common
drawback
of
these
proposal
is
that
they
can
adapt
to
varying
workloads
on
large
timescales
well
beyond
the
latency
constraints
of
networking
applications
Moreover
they
operate
at
cluster
level
as
opposed
to
the
single
server
router
we
consider
and
that
makes
their
solution
hard
to
apply
to
our
problem
Closer
to
our
focus
is
recent
work
looking
at
single
server
energy
proportionality
Some
focus
on
improved
hardware
capabilities
for
power
management
The
remaining
focus
like
us
on
leveraging
existing
hardware
support
but
do
so
in
the
context
of
very
different
application
workloads
Tsirogiannis
et
al
focus
on
database
workloads
and
evaluate
the
energy
efficiency
of
current
query
optimizers
The
authors
in
focus
on
non
interactive
jobs
in
data
centers
and
advocate
the
use
of
system
wide
sleep
states
described
in
sec
background
during
idle
times
They
use
analytical
models
and
simulations
to
demonstrate
the
potential
power
savings
This
approach
however
assumes
relatively
long
periods
on
the
order
of
tens
of
milliseconds
and
greater
of
idleness
across
memory
and
CPUs
As
such
their
results
and
states
more
generally
are
not
applicable
to
typical
network
equipment
that
even
if
lightly
utilized
is
never
completely
idle
More
recently
Meisner
explore
power
management
trade
offs
for
online
data
intensive
services
such
as
web
search
online
ads
etc
This
class
of
workloads
like
ours
face
stringent
latency
requirements
and
large
quick
variations
in
load
Using
benchmarks
the
authors
in
derive
analytical
models
to
study
the
latency
tradeoffs
of
power
management
options
based
on
which
they
offer
general
recommendations
for
hardware
designers
of
future
energy
efficient
architectures
In
contrast
to
the
above
we
focus
on
networking
workloads
and
exploiting
low
power
options
in
current
hardware
The
result
of
our
exploration
is
lightweight
online
power
saving
algorithm
that
we
validate
in
real
system
We
leave
it
to
future
work
to
generalize
our
findings
to
application
workloads
beyond
networking
Deconstructing
Power
Usage
necessary
step
before
attempting
the
design
of
power
proportional
router
is
to
understand
the
contribution
of
each
server
component
to
the
overall
power
usage
Isolating
the
power
consumption
at
component
level
will
guide
us
towards
those
components
that
offer
the
best
opportunities
for
increasing
power
efficiency
Server
architecture
For
our
study
we
chose
an
off
the
shelf
server
based
on
the
Intel
Xeon
processor
that
is
commonly
used
in
datacenter
and
enterprise
environments
The
overall
architecture
is
similar
to
that
in
servers
from
other
manufacturers
Figure
shows
simplified
diagram
of
the
components
that
make
up
the
server
our
server
has
two
CPU
processors
each
of
which
consists
of
six
cores
packaged
onto
single
die
along
with
several
uncore
components
caches
memory
controllers
power
control
unit
etc
The
two
processors
are
Xeon
Westmere
with
maximum
clock
frequency
of
GHz
They
are
connected
to
each
other
and
to
the
hub
via
dedicated
point
to
point
links
called
QuickPath
Interconnect
in
our
case
The
memory
chips
of
GB
is
directly
connected
to
each
of
the
processors
We
equipped
the
server
with
two
dual
port
Intel
Gbps
Ethernet
Network
Interface
Cards
NICs
The
hub
interfaces
to
the
NICs
via
PCIe
and
to
additional
chipsets
on
the
motherboard
that
control
other
peripherals
Other
discrete
components
include
the
power
supply
and
the
fans
From
power
perspective
we
consider
only
the
components
that
consume
non
negligible
amount
of
power
CPUs
memory
NICs
fans
and
the
motherboard
We
use
the
term
motherboard
as
generic
term
to
include
components
like
the
Hub
and
PCIe
bridge
It
also
includes
other
system
peripherals
not
directly
used
in
our
tests
USB
controller
SATA
controller
video
card
and
so
forth
The
power
supply
unit
PSU
delivers
power
to
all
components
using
single
DC
line
to
the
motherboard
which
is
in
turn
responsible
for
distributing
power
to
all
other
subsystems
CPUs
fans
etc
We
measure
the
current
absorbed
by
the
system
by
reading
the
voltage
across
shunt
resistors
placed
in
series
to
the
line
This
gives
us
the
ability
to
measure
power
with
high
accuracy
and
high
sampling
frequency
and
excludes
from
the
measurement
the
efficiency
of
the
PSU
which
is
non
linear
and
can
be
quite
low
in
certain
cases



Shunt
resistors
hence
individual
power
readings
are
also
used
for
the
two
Gbps
NICs
the
cards
are
connected
using
PCIe
riser
boards
with
shunt
resistors
on
the
power
supply
lines
Workload
Our
server
runs
Linux
and
Click
with
Ethernet
device
driver
with
support
for
multiple
receive
and
transmit
queues
Using
multiple
queues
feature
available
in
all
modern
high
speed
NICs
we
can
make
sure
each
packet
is
handled
from
reception
to
transmission
by
only
one
core
without
contention
We
use
Receive
Side
Scaling
RSS
on
the
NIC
to
define
the
number
of
queues
and
hence
the
number
of
cores
that
will
process
traffic
RSS
selects
the
receive
queue
of
packet
using
the
result
of
hash
computed
on
the
tuple
of
the
packet
header
This
way
traffic
is
evenly
spread
across
queues
and
cores
with
packets
belonging
to
the
same
flow
always
processed
by
the
same
core
In
the
rest
of
the
paper
when
we
refer
to
number
of
cores
we
also
imply
that
there
are
independent
receive
queues
The
device
drivers
allows
us
to
select
the
number
of
queues
that
will
receive
packets
and
the
incoming
packets
are
uniformly
spread
across
all
queues
using
hash
computed
on
the
packet
header
In
all
results
in
this
paper
there
is
always
one
to
one
mapping
between
cores
and
queues
For
example
when
we
refer
to
active
cores
we
also
imply
that
input
traffic
is
spread
uniformly
across
active
queues
In
Section
we
will
describe
the
NIC
support
for
multiple
queues
in
greater
detail
In
the
following
sections
we
first
focus
on
the
performance
and
power
consumption
of
single
server
operating
as
an
IPv
router
with
four
ports
Later
in
sec
evaluation
we
consider
more
advanced
packet
processing
applications
such
as
NetFlow
AES
encryption
and
redundancy
elimination
For
traffic
generation
we
use
additional
servers
that
are
set
up
to
generate
either
synthetic
workloads
with
fixed
size
packets
or
trace
driven
workloads
We
used
two
machines
identical
to
our
router
server
each
generator
sends
packets
on
two
Gbps
interfaces
using
multiple
cores
associated
to
multiple
RSS
queues
in
order
to
maximize
the
packet
rate
In
Routebricks
cluster
each
server
is
in
charge
of
one
or
more
external
router
interfaces
and
is
directly
connected
to
all
other
servers
via
Gbps
internal
links
The
internal
links
need
to
operate
at
rate
equal
to
where
is
the
external
line
rate
Gbps
in
our
experiments
and
is
the
total
number
of
servers
in
our
setup
That
is
the
internal
links
will
at
most
carry
Gbps
of
traffic
in
each
direction
receive
and
transmit
Power
characterization
Isolating
the
power
consumption
of
each
component
is
useful
to
answer
two
different
questions
where
does
the
power
go
in
modern
server
how
does
the
power
consumption
vary
with
load
The
answer
to
the
first
question
will
let
us
focus
on
the
most
important
components
as
they
are
the
ones
from
which
we
can
gain
the
largest
benefit
The
second
question
will
tell
us
how
much
we
can
potentially
gain
from
those
efforts
The
answer
to
the
first
question
will
let
us
identify
which
components
are
the
largest
consumers
while
the
answer
to
the
second
question
tells
us
how
much
we
can
potentially
save
by
making
that
component
more
energy
proportional
An
ideal
component
to
focus
on
is
one
that
consumes
large
fraction
of
the
total
power
and
whose
consumption
varies
significantly
with
the
input
load
We
measure
power
in
three
sets
of
experiments
an
idle
system
without
Click
running
system
running
Click
with
no
input
traffic
system
running
Click
and
forwarding
Gbps
over
four
interfaces
Given
that
we
have
only
one
aggregate
power
measurement
for
the
entire
server
plus
one
dedicated
to
the
NICs
we
need
to
perform
several
measurements
to
isolate
each
component
The
system
has
eight
fans
two
CPUs
and
six
memory
chips
For
each
scenario
we
measure
the
power
with
all
components
and
then
we
physically
remove
one
component
memory
chip
CPU
or
fan
and
then
measure
the
power
The
difference
is
then
the
power
consumed
by
that
component
in
that
scenario
Comparing
the
measurements
with
individual
components
added
or
removed
we
can
derive
the
contribution
of
each
of
them
as
shown
in
Figure
Figure
shows
the
results
of
our
experiments
with
IPv
routing
At
peak
the
system
reaches
the
idle
power
consumption
of
With
Click
running
and
no
traffic
the
power
consumption
is
which
is
less
than
lower
than
the
peak
power
Several
design
considerations
stem
from
the
results
in
Figure
These
measurements
first
confirm
that
certain
components
motherboard
and
fans
are
not
affected
by
load
or
power
saving
states
The
power
consumption
of
NICs
varies
with
the
traffic
from
XX
to
XX
each
but
the
contribution
to
the
total
is
relatively
limited
Any
power
saving
state
on
the
NIC
Surely
we
do
not
exploit
it
Another
component
that
exhibits
dependency
on
the
load
is
main
memory
here
the
power
goes
from
XX
to
XX
under
load
Despite
the
relatively
modest
contribution
to
the
total
variations
are
quite
large
and
certainly
suggest
that
when
possible
software
should
try
to
reduce
the
number
of
memory
accesses
XXX
Too
trivial
The
CPUs
are
clearly
the
dominant
component
when
it
comes
to
power
usage
Even
when
all
cores
are
idle
they
consume
almost
half
of
the
total
idle
power
or
each
That
energy
is
mostly
used
to
keep
the
uncore
online
At
peak
the
CPUs
reach
each
which
is
about
four
times
their
idle
power
this
contributes
significantly
to
the
more
than
doubling
of
the
total
system
power
compared
to
idle
The
other
system
components
contribute
little
to
the
overall
power
consumption
The
motherboard
the
component
with
the
second
largest
power
draw
reaches
and
it
does
not
vary
from
idle
to
peak
load
The
memory
and
NICs
exhibit
significant
dynamic
range
peak
power
is
about
twice
the
idle
power
but
the
overall
contribution
is
quite
limited
for
the
six
memory
chips
and
for
the
four
Gbps
interfaces
The
system
idle
power
is
relatively
high
at
Even
though
this
is
an
ongoing
concern
for
system
architects
the
general
trend
is
towards
reduction
in
idle
power
Figure
shows
the
idle
power
of
number
of
systems
since
as
reported
by
SpecPower
The
plot
shows
clear
downward
trend
in
idle
system
power
halving
in
only
years
In
the
near
future
this
trend
will
continue
by
integrating
more
components
into
the
CPUs
and
designing
more
energy
efficient
NICs
and
memory
chips
Finally
the
software
stack
exhibits
very
poor
power
scaling
the
total
power
consumption
is
almost
constant
at
zero
and
full
load
Click
continuously
polls
the
network
interface
to
look
for
incoming
packets
While
this
mechanism
allows
to
easily
achieve
high
throughput
it
also
prevents
the
CPU
from
being
idle
even
in
absence
of
traffic
We
also
validated
that
this
behaviour
is
consistent
across
the
entire
spectrum
of
traffic
scenarios
Figure
shows
the
system
power
usage
when
running
at
different
rates
with
different
packet
sizes
from
to
The
power
curve
is
flat
around
The
reason
as
discussed
in
is
that
the
Click
software
uses
continuous
polling
loop
to
determine
when
traffic
is
available
Therefore
the
CPUs
run
at
full
load
irrespective
of
traffic
patterns
In
fact
careful
analysis
of
the
data
in
Figure
reveals
that
the
CPUs
draw
more
power
with
no
traffic
than
with
traffic
That
is
because
in
absence
of
traffic
the
polling
loop
is
quite
short
and
always
reads
memory
location
that
is
present
in
cache
As
soon
as
packets
arrive
caches
are
invalidated
resulting
in
some
cache
misses
and
consequent
stalls
of
the
cores
waiting
for
the
memory
reads
to
complete
We
conjecture
that
those
stalls
make
the
processors
do
less
work
and
thus
draw
less
power
In
summary
our
analysis
indicates
that
to
achieve
energy
efficiency
we
should
focus
on
controlling
the
CPUs
as
they
draw
the
most
power
and
exhibit
the
largest
dynamic
range
from
idle
to
peak
In
the
following
section
we
explore
the
mechanisms
available
to
software
developers
for
controlling
CPU
power
usage
Server
Support
for
Power
Management
Modern
servers
provide
variety
of
power
management
mechanisms
that
operate
at
all
levels
in
the
platform
Here
we
briefly
summarize
the
basic
controls
that
are
exposed
to
the
operating
system
Core
idle
states
states
Each
core
in
package
can
be
independently
put
into
one
of
several
low
power
or
idle
states
which
are
numbered
from
to
Cn
The
state
is
present
on
all
platforms
and
refers
to
core
that
is
executing
instructions
and
consuming
the
highest
amount
of
power
Higher
numbered
states
indicate
that
successively
larger
portion
of
the
core
is
turned
off
resulting
in
lower
power
draw
The
Westmere
processors
we
use
offer
three
states
and
core
enters
into
state
either
by
executing
HALT
or
MONITOR
MWAIT
instruction
states
are
exited
to
return
to
the
state
when
the
desired
event
interrupt
or
write
access
to
the
monitored
memory
range
occurs
Considering
the
larger
amount
of
circuitry
turned
off
higher
idle
states
take
longer
to
revert
back
to
the
fully
operational
state
The
time
to
return
from
higher
numbered
state
back
to
is
termed
the
exit
latency
of
the
state
As
an
example
when
in
the
core
is
clock
gated
the
clock
distribution
into
the
core
is
blocked
but
the
core
is
still
drawing
power
Going
from
to
only
requires
the
clock
distribution
to
be
re
enabled
thus
the
time
it
takes
to
execute
the
first
instruction
after
being
in
is
comparable
to
that
of
cache
miss
In
the
and
caches
are
flushed
and
turned
off
In
the
core
is
additionally
power
gated
power
distribution
into
the
core
is
disabled
after
the
core's
state
is
written
to
reserved
part
of
the
cache
Consequently
the
time
to
enter
exit
and
is
much
higher
due
to
the
need
to
save
and
restore
state
and
to
allow
the
voltage
levels
to
stabilize
We
measure
exit
latencies
for
states
in
sec
power
tradeoffs
Processor
performance
states
states
While
processor
core
is
in
active
state
its
power
consumption
is
determined
by
the
voltage
and
operating
frequency
which
can
be
changed
with
Dynamic
Voltage
and
Frequency
Scaling
DVFS
In
DVFS
voltage
and
frequency
are
scaled
in
tandem
Modern
processors
offer
number
of
frequency
and
voltage
combinations
each
of
which
is
termed
state
is
the
highest
performing
state
pegged
at
the
maximum
voltage
required
by
the
highest
operating
frequency
subsequent
states
operate
at
progressively
lower
frequencies
and
voltages
Transitions
between
states
require
time
to
stabilize
the
frequency
but
the
transition
can
be
applied
while
the
processor
is
executing
instructions
states
affect
the
entire
CPU
and
all
cores
always
run
at
the
same
frequency
The
processor
in
our
system
offers
states
with
frequencies
ranging
from
GHz
to
GHz
Even
without
halting
core
we
can
reduce
its
power
consumption
by
changing
the
operating
voltage
and
frequency
with
technique
called
Dynamic
Voltage
and
Frequency
Scaling
DVFS
Voltage
and
Frequency
Scaling
operate
in
tandem
because
for
each
operating
frequency
the
circuits
requires
minimum
voltage
to
operate
reliably
In
fact
reducing
the
supply
voltage
transistors
take
longer
to
switch
and
signals
take
longer
to
propagate
To
maintain
stability
and
correctness
the
operating
frequency
must
also
be
reduced
The
processor
offers
number
of
frequency
voltage
combinations
called
states
at
which
it
can
operate
State
is
the
highest
performing
state
pegged
at
the
maximum
voltage
required
by
the
highest
operating
frequency
subsequent
states
use
progressively
lower
frequency
and
voltage
The
transition
from
state
to
another
requires
time
to
stabilize
the
frequency
but
the
transition
can
be
applied
while
the
processor
is
actively
executing
instructions
Since
the
frequency
is
driven
by
the
PLL
which
involves
feedback
loop
there
is
latency
associated
with
switching
between
states
and
this
is
the
time
required
for
the
PLL
to
stabilize
the
frequency
While
in
general
cores
can
have
independent
power
planes
the
processors
we
use
incorporate
shared
voltage
rail
across
the
cores
which
forces
shared
state
across
the
cores
Effectively
all
the
cores
run
at
frequency
that
is
dictated
by
the
most
hungry
core
With
few
exceptions
traditional
server
architectures
consist
of
microprocessor
that
connects
to
the
rest
of
the
system
with
pair
of
interconnection
hubs
fast
northbridge
which
connects
the
processors
with
memory
and
graphics
via
front
side
bus
and
slower
southbridge
chipset
which
handles
the
interface
between
the
processor
and
slower
peripheral
devices
SATA
USB
and
so
on
More
contemporary
processors
do
away
with
discrete
northbridge
chip
and
instead
integrate
the
functionality
on
the
processor
die
itself
Figure
depicts
the
most
relevant
parts
of
the
server
platform
this
particular
figure
reflects
the
latest
Intel
server
architecture
and
differs
from
previous
versions
in
two
respects
it
features
dedicated
memory
channels
from
processors
to
memory
and
ii
it
uses
high
speed
Quick
Path
Interconnect
QPI
bus
that
interconnects
individual
processors
and
also
connects
them
to
the
hub
IOH
which
has
supplanted
the
traditional
southbridge
These
enhancements
improve
performance
by
reducing
memory
access
latency
reduced
latency
by
integrating
the
northbridge
functionality
onto
the
processor
package
and
providing
full
duplex
communication
on
the
QPI
interface
In
Figure
we
differentiate
between
components
on
the
motherboard
and
accessories
that
plug
into
it
which
are
drawn
in
solid
colors
along
the
edges
Servers
are
optimized
for
high
throughput
and
performance
and
incorporate
parts
with
high
thermal
dissipation
power
or
TDP
in
general
higher
performance
implies
higher
TDP
and
are
designed
to
be
efficient
only
at
the
the
upper
end
of
the
load
range
higher
power
consumption
but
perhaps
better
throughput
watt
Even
as
recently
as
it
was
shown
that
servers
consumed
of
the
maximum
power
while
idle
and
exhibited
small
dynamic
range
Since
that
time
there
have
been
significant
advances
in
power
management
particularly
in
processor
architectures
which
enable
processors
to
be
very
efficient
through
the
load
range
not
just
as
the
higher
end
Admittedly
the
rest
of
the
platform
has
lagged
behind
but
given
the
increased
focus
on
these
components
we
will
be
able
to
see
similar
efficiency
mechanisms
take
effect
across
the
entire
system
In
the
next
section
we
detail
some
of
the
power
saving
mechanisms
that
help
processors
manage
power
and
scale
their
consumption
proportional
to
the
load
Power
management
in
the
processor
and
also
on
the
larger
system
is
accomplished
in
two
ways
which
sometimes
take
place
in
tandem
by
placing
components
in
various
low
power
states
and
ii
power
gating
which
effectively
shuts
off
power
to
component
Low
power
states
are
enabled
by
hardware
support
for
states
states
states
and
platform
states
Of
these
the
first
three
are
defined
for
the
processor
package
while
the
last
is
defined
for
the
entire
platform
These
states
are
actuated
in
one
of
two
ways
of
these
states
is
handled
either
by
software
most
often
the
OS
calling
ACPI
Advanced
Configuration
and
Power
Interface
routines
or
ii
directly
handled
by
microcode
inside
the
power
control
unit
this
is
the
case
the
very
low
level
power
states
that
are
not
exposed
to
the
OS
In
the
following
we
briefly
describe
each
of
the
power
management
states
Additional
power
states
For
completeness
we
briefly
mention
two
additional
power
state
classes
Throttle
states
states
are
used
to
prevent
the
processor
from
being
damaged
when
power
dissipation
approaches
the
thermal
limit
They
cannot
be
controlled
from
software
Throttle
states
states
force
the
processor
frequency
to
be
lowered
when
power
dissipation
approaches
the
thermal
limit
to
prevent
the
processor
from
being
damaged
states
cannot
be
controlled
from
software
states
are
defined
for
the
entire
system
not
just
the
processor
is
the
active
state
while
in
higher
states
portions
of
the
system
are
turned
off
after
saving
their
state
to
RAM
or
persistent
storage
The
states
reflect
various
degrees
of
system
wide
sleep
and
correspond
to
the
familiar
stand
by
and
hibernation
modes
of
laptops
and
desktop
The
transition
times
involved
in
the
states
are
measured
in
seconds
which
is
much
higher
than
the
latencies
we
can
tolerate
and
hence
we
do
not
consider
them
in
our
work
Addressing
Software
Inefficiencies
pre
requisitive
to
exploiting
low
power
states
is
to
ensure
that
the
software
stack
itself
is
efficient
doesn't
engage
in
needless
work
that
prevents
the
creation
of
idle
periods
We
saw
from
Figure
that
Click's
polling
architecture
causes
our
server's
power
consumption
to
be
the
same
at
zero
load
no
packets
and
at
full
bit
rate
This
section
briefly
describes
how
we
fix
this
source
of
inefficiency
Broadly
speaking
designing
software
to
reduce
power
usage
calls
for
applying
three
strategies
maximizing
idle
time
minimize
the
power
draw
when
idle
when
resuming
work
use
the
system
components
in
the
most
energy
efficient
way
In
our
case
the
only
knobs
available
to
us
to
implement
these
strategies
are
the
states
states
and
the
number
of
cores
we
allocate
to
process
packets
The
challenge
software
developers
face
is
that
these
three
strategies
are
highly
interdependent
design
decision
for
one
may
affect
the
benefit
we
can
derive
from
the
others
For
example
assigning
more
cores
at
higher
frequency
to
forward
packets
allows
the
system
to
drain
the
queues
faster
and
thus
increase
the
idle
time
However
the
overall
system
could
be
less
energy
efficient
if
power
savings
from
idle
time
do
not
compensate
the
additional
power
required
to
process
packets
faster
The
same
is
true
for
the
second
step
Minimizing
idle
power
by
making
the
cores
enter
for
example
requires
time
to
save
state
when
the
core
is
not
doing
useful
work
but
still
consumes
power
The
time
spent
to
enter
could
have
decided
against
this
REWRITE
there
are
three
approaches
increase
idle
time
reduce
power
when
idle
find
the
most
energy
efficient
operating
point
when
processing
packets
They
are
not
independent
Finding
an
energy
efficient
operating
point
will
impact
the
idle
time
and
the
opportunity
to
go
to
deep
power
down
state
Hence
it
depends
on
the
relative
benefits
of
each
here
we
look
at
and
Next
section
will
look
at
As
described
in
the
previous
section
the
power
consumed
by
the
CPU
can
be
reduced
via
software
either
by
putting
cores
into
higher
states
when
it
is
idle
or
by
using
higher
states
when
it
is
active
When
the
system
has
multiple
cores
we
can
also
reduce
power
consumption
by
scaling
the
number
of
active
cores
to
match
the
current
load
Thus
reasonable
software
framework
to
make
the
system
power
proportional
use
less
power
when
not
fully
loaded
will
require
three
mechisms
to
be
supported
identifying
opportunities
for
system
pacing
create
opportunities
to
reduce
power
between
busy
periods
ii
disable
and
power
down
cores
when
not
needed
and
quickly
turning
them
on
in
response
to
load
increases
and
iii
identify
the
operating
point
how
many
cores
and
running
at
what
frequency
that
can
support
the
current
load
while
using
the
least
amount
of
power
In
order
to
exploit
the
two
knobs
states
states
made
available
to
software
to
control
power
usage
we
need
to
create
opportunities
to
slow
down
or
power
down
portions
of
the
system
make
sure
that
disabled
components
can
be
quickly
re
enabled
if
the
workload
increases
and
for
each
load
level
find
the
operating
point
that
maximizes
power
efficiency
In
this
section
we
understand
the
feasibility
and
quantify
the
reduction
in
power
that
may
be
achieved
by
the
first
two
mechanisms
in
the
specific
context
of
packet
processing
workloads
We
defer
discussion
of
finding
the
optimal
operating
point
to
the
next
section
All
results
in
this
section
are
derived
using
standard
IPv
workloads
using
fixed
size
packets
Traditionally
operating
systems
and
device
drivers
implemented
packet
processing
via
interrupt
handlers
incoming
packets
generate
an
interrupt
that
is
processed
by
the
CPU
This
approach
impacts
performance
each
packet
causes
context
switch
and
pays
the
interrupt
handling
penalty
and
is
also
prone
to
livelock
at
higher
loads
To
get
around
this
Click
disables
interrupts
on
the
network
card
and
resort
to
polling
the
interface
when
the
CPU
is
not
busy
While
this
does
provide
higher
performance
this
also
means
the
CPU
does
not
have
idle
periods
where
it
can
be
put
in
low
power
states
The
Linux
NAPI
packet
processing
framework
addresses
this
problem
with
hybrid
approach
Interrupts
still
wake
up
the
CPU
and
schedule
the
packet
processing
thread
However
the
packet
processing
routine
disables
interrupts
and
switches
to
polling
mode
while
there
are
still
packets
in
the
input
queue
After
the
queue
is
drained
or
maximum
batch
of
packets
has
been
processed
the
routine
ends
and
interrupts
are
re
enabled
We
modified
the
driver
and
Click
to
operate
in
similar
fashion
we
refer
to
the
resultant
stack
as
NAPI
Click
Each
receive
queue
of
an
interface
raises
different
interrupt
that
is
directed
to
the
core
that
is
handling
that
queue
Figure
shows
the
power
savings
with
NAPI
Click
vs
unmodified
polling
mode
Click
for
different
packet
rates
We
see
that
using
NAPI
reduces
power
consumption
by
in
idle
mode
and
when
forwarding
Gbps
of
packets







We
should
also
discuss
the
per
bit
cost
in
terms
of
power
Until
now
we
have
only
considered
the
per
packet
cost
Looking
at
Figure
and
Figure
we
see
that
with
polling
the
power
consumed
at
Gbps
with
packets
is
higher
than
the
power
consumed
with
no
traffic
in
contrast
with
our
previous
statement
This
is
due
to
the
power
increase
for
memory
and
NICs
at
high
bit
rates
On
the
performance
side
enabling
interrupts
has
no
impact
on
the
maximum
packet
rate
the
router
can
forward
Mpps
with
packets
Another
performance
metric
of
interest
is
packet
processing
latency
Additional
latency
may
be
caused
by
the
hardware
rate
limiting
interrupts
and
by
the
interrupt
processing
required
before
running
the
polling
routine
To
measure
the
latency
we
ran
experiments
using
server
with
two
network
interfaces
forwarding
packets
from
one
to
the
other
interface
in
tight
loop
different
machine
acts
as
sender
and
receiver
and
timestamps
outgoing
and
incoming
packets
using
the
hardware
timestamp
counter
In
an
unloaded
system
and
without
NIC
level
batching
the
latency
is
about
with
polling
and
with
NAPI
Click
At
high
load
the
latencies
of
the
two
methods
tend
to
converge
as
NAPI
Click
degenerates
to
polling
at
high
load
In
the
interest
of
space
we
refer
the
reader
to
for
more
exhaustive
description
of
our
setup
and
analysis
of
the
latency
results
To
conclude
the
hybrid
interrupt
polling
solution
allows
us
to
scale
the
power
consumption
between
high
load
when
polling
is
used
and
power
consumption
is
high
and
low
load
when
switching
to
interrupts
drives
power
consumption
down
for
negligible
impact
on
latency
Using
core
idle
states
Interrupts
allow
the
software
to
stop
polling
the
interface
and
transition
the
cores
to
low
power
state
By
default
the
Linux
kernel
chooses
the
state
natural
question
is
why
not
entering
higher
state
such
as
or
Recall
from
Section
that
higher
states
yield
better
power
savings
but
at
the
price
of
longer
exit
latency
In
order
to
precisely
quantify
the
power
savings
vs
exit
latency
trade
off
we
first
determine
the
power
usage
of
the
various
states
Figure
and
measure
their
exit
latencies
Figure
Another
place
where
the
tradeoff
between
power
saving
and
latency
is
the
use
of
deep
sleep
states
Once
again
we
need
to
measure
the
power
savings
and
the
latency
and
possibly
loss
induced
by
the
use
of
such
states
in
the
context
of
high
speed
software
routers
As
mentioned
in
Section
modern
CPU
package
contains
several
computation
cores
and
shared
uncore
block
that
implements
functions
shared
by
the
core
Cores
can
be
powered
down
using
one
of
the
available
states
individually
the
uncore
can
only
be
powered
down
completely
when
all
cores
are
in
the
lowest
state
The
power
savings
come
at
the
price
of
an
exit
latency
the
time
to
return
to
the
active
state
Deeper
sleep
states
save
more
power
but
at
the
cost
of
higher
longer
exit
latency
On
the
Westmere
CPU's
used
in
our
work
the
cores
support
three
sleep
states
and
as
described
in
Section
To
understand
the
relative
power
draws
in
the
sleep
states
we
measure
the
power
of
the
CPUs
by
putting
individual
cores
manually
to
or
Figure
shows
that
with
all
cores
in
the
system
can
shed
an
additional
When
all
cores
are
in
the
system
power
usage
is
down
to
that
is
of
the
power
consumed
when
all
the
cores
are
in
We
also
verified
that
the
power
savings
of
transitioning
to
deep
power
down
state
are
equally
distributed
across
the
cores
We
measured
the
exit
latencies
indirectly
with
an
approach
similar
to
that
in
Section
we
measure
the
delay
of
packets
through
software
router
driven
by
traffic
at
very
low
packet
rate
packet
sec
When
an
interrupt
arrives
the
core
must
first
exit
from
its
state
depending
on
the
experiment
and
then
packet
processing
can
begin
Due
to
the
low
packet
rate
cores
have
plenty
of
time
to
return
to
deep
power
down
state
before
the
next
interrupt
Figure
plots
the
packet
delay
minimum
maximum
average
depending
on
the
state
The
forwarding
latencies
in
and
are
practically
the
same
This
validates
that
the
exit
latency
from
is
comparable
to
cache
miss
Waking
up
from
deep
power
down
state
instead
requires
longer
time
for
and
about
for
large
exit
latency
is
potentially
problematic
if
it
causes
packets
to
be
dropped
At
line
rate
the
exit
latency
of
translates
into
packets
that
need
to
be
buffered
by
the
NIC
packets
This
assumes
back
to
back
packets
and
taking
into
account
the
byte
spacing
between
packets
required
by
the
Gigabit
Ethernet
standard
If
the
core
is
in
we
would
need
to
buffer
packets
or
packets
Note
that
the
exit
latency
from
to
is
few
nanoseconds
and
this
wouldn't
require
any
packets
to
be
buffered
The
network
interfaces
used
in
our
system
fairly
typical
of
high
speed
NICs
have
receive
queues
that
can
accommodate
up
to
packets
which
is
almost
three
times
the
capacity
required
in
the
worst
case
scenario
core
in
Thus
putting
cores
to
sleep
and
waking
them
up
to
process
incoming
packets
introduces
small
additional
latency
but
is
not
likely
to
cause
packet
drops
REWRITE
The
takeaway
here
is
that
keeping
one
core
in
state
ready
to
process
packets
and
turning
on
additional
cores
from
deep
sleep
states
allows
the
network
operator
to
save
up
to
or
about
of
the
entire
system
power
for
latency
penalty
of
up
to
in
the
worst
case
Note
that
only
packets
at
the
beginning
of
the
burst
suffer
this
latency
once
the
core
is
active
and
begins
to
poll
the
interface
subsequent
packets
see
not
additional
latency
Given
that
turning
off
cores
is
feasible
and
can
save
power
in
the
next
section
we
look
at
the
question
of
sizing
deciding
how
many
cores
need
be
turned
on
to
satisfy
fixed
traffic
demand
Studying
the
Design
Space
We
now
turn
to
exploring
the
design
space
of
power
saving
algorithms
system
developer
has
three
knobs
by
which
to
control
CPU
power
usage
the
number
of
cores
allocated
to
process
traffic
the
frequency
at
which
the
cores
run
and
the
sleep
state
that
cores
use
when
there
is
no
traffic
to
process
Unfortunately
the
literature
in
this
space
does
not
offer
solution
that
can
be
easily
adapted
to
our
workload
Research
results
based
on
empirical
results
focus
on
very
different
workloads
such
as
database
transactions
web
and
enterprise
services
datacenter
workloads
In
those
contexts
new
jobs
arrive
at
relatively
large
timescales
in
the
order
of
microseconds
or
milliseconds
compared
to
high
speed
networks
In
our
workload
for
example
processing
several
millions
of
packets
second
means
that
new
packets
arrive
every
few
hundreds
of
nanoseconds
Further
processing
latency
is
major
design
constraint
where
each
packet
must
be
forwarded
withing
few
tens
of
to
minimize
impact
on
end
to
end
network
delay
Research
papers
that
look
at
networking
workloads
consider
abstract
power
and
system
models
that
as
we
will
see
in
the
rest
of
this
section
do
not
map
directly
to
the
system
behavior
As
such
the
recommendations
of
those
works
cannot
be
easily
translated
to
algorithms
for
current
servers
The
challenge
is
how
and
when
to
use
each
of
these
knobs
to
maximize
energy
savings
We
first
consider
the
single
core
case
and
then
extend
our
analysis
to
multiple
cores
Our
exploration
is
based
on
combination
of
empirical
analysis
and
simple
theoretical
models
the
latter
serving
to
build
intuition
for
why
our
empirical
results
point
us
in
particular
direction
Single
core
case
With
just
one
core
to
consider
we
are
left
with
two
design
knobs
and
our
design
options
boil
down
to
one
question
is
it
more
efficient
to
run
the
core
at
lower
frequency
for
longer
period
of
time
or
run
the
core
at
relatively
higher
frequency
for
shorter
period
of
time
and
then
spend
the
remaining
time
in
sleep
state
To
understand
which
option
is
superior
we
compare
two
extreme
options
by
which
one
might
process
packets
in
time
the
hare
the
core
runs
at
its
maximum
frequency
and
then
enters
low
power
sleep
state
or
below
This
strategy
is
sometimes
referred
to
as
race
to
idle
as
cores
try
to
maximize
their
idle
time
the
tortoise
the
core
runs
at
the
minimum
frequency
required
to
process
the
input
rate
of
we
pick
core
frequency
such
that
there
is
no
idle
time
This
is
form
of
just
in
time
strategy
To
compare
the
two
strategies
we
can
write
the
total
energy
consumption
of
one
core
over
the
period
as
where
The
first
term
accounts
for
the
energy
used
when
actively
processing
packets
is
the
active
power
at
frequency
and
is
the
time
required
to
process
packets
at
frequency
The
second
term
considers
the
energy
required
to
transition
in
and
out
of
sleep
state
to
store
retrieve
core
state
stabilize
the
clock
etc
The
third
term
is
the
energy
consumption
when
idle
With
the
tortoise
strategy
the
core
runs
at
frequency
such
that
and
no
idle
time
hence
With
the
hare
strategy
and
hence
To
facilitate
comparison
let's
assume
for
now
that
instantaneous
transitions
to
sleep
states
and
an
ideal
system
with
zero
idle
power
Note
that
these
assumptions
greatly
favor
any
hare
like
strategy
With
these
assumption
the
comparison
between
the
tortoise
and
hare
boils
down
to
comparison
of
their
terms
in
Equations
and
The
literature
on
component
level
chip
power
models
tell
us
that
the
active
power
for
component
using
frequency
voltage
scaling
grows
faster
than
but
slower
than





The
term
instead
scales
as
in
the
best
case
Hence
putting
these
together
we
would
expect
that
is
always
greater
than
since
Hence
despite
our
very
hare
friendly
assumptions
basic
chip
power
models
would
tell
us
that
it
is
better
to
behave
like
tortoise
than
hare
Do
experimental
results
agree
with
the
above
reasoning
To
answer
this
we
use
the
same
experimental
setup
as
in
sec
measurement
with
workload
of
packets
and
plot
results
for
our
server
using
between
to
cores
We
show
results
with
more
than
just
one
core
to
ensure
we
aren't
inadvertently
missing
trend
that
arises
with
multiple
cores
in
all
cases
however
we
only
draw
comparisons
across
tests
that
use
the
same
number
of
cores
unlike
the
comparisons
we
draw
in
the
following
section
We
first
look
at
how
scales
with
in
practice
Fig
plots
the
active
power
consumption
as
function
of
frequency
For
each
data
point
we
measure
power
at
the
maximum
input
packet
rate
that
cores
can
sustain
at
that
frequency
this
ensures
zero
idle
time
and
hence
that
we
are
indeed
measuring
only
We
see
that
does
not
grow
as
fast
as
our
model
predicted
halving
the
frequency
leads
to
drop
of
only
about
in
power
usage
with
one
core
up
to
maximum
of
with
twelve
cores
The
reason
for
this
is
that
in
practice
many
of
the
server's
components
both
within
the
CPU
caches
and
memory
controllers
and
external
to
the
CPU
memory
and
subsystems
are
not
subject
to
frequency
and
voltage
scaling
and
this
leads
to
lower
savings
than
predicted
Thus
active
power
consumption
grows
much
more
slowly
with
frequency
than
expected
What
about
Since
the
processing
time
dictates
the
forwarding
rate
core
can
sustain
we
look
at
the
forwarded
packet
rate
corresponding
to
each
of
the
data
points
from
Fig
and
show
the
results
in
Fig
Once
again
we
see
that
our
model's
predictions
fall
short
doubling
the
frequency
does
not
double
the
sustainable
packet
rate
For
example
with
one
core
doubling
the
frequency
from
GHz
to
GHz
leads
to
an
increase
of
approx
in
the
forwarded
packet
rate
down
to
with
twelve
cores
Why
is
this
Our
conjecture
is
that
the
perfect
scaling
of
processing
time
applies
only
to
CPU
intensive
workload
Packet
processing
however
is
very
memory
and
intensive
and
access
times
for
memory
and
do
not
scale
with
frequency
Therefore
as
we
increase
the
frequency
we
arrive
at
point
where
the
CPU
does
its
work
faster
and
faster
but
it
is
then
stalled
waiting
for
memory
accesses
to
complete
leading
to
point
where
increasing
the
frequency
no
longer
improves
productivity
In
summary
we
find
that
grows
more
slowly
than
expected
with
frequency
but
at
the
same
time
decreases
more
slowly
than
expected
Where
does
this
leave
the
product
We
cannot
directly
measure
this
product
energy
and
hence
we
look
at
efficiency
in
terms
of
packets
forwarded
per
Joule
obtained
by
dividing
the
maximum
sustained
forwarding
rate
from
Fig
by
the
power
consumption
Fig
The
result
is
shown
in
Fig
for
increasing
frequency
As
before
this
captures
system
efficiency
while
actively
processing
work
there's
no
idle
time
We
see
that
empirically
running
at
the
maximum
frequency
is
marginally
more
energy
efficient
in
all
configurations
That
is
if
our
assumptions
of
were
to
hold
then
the
hare
would
actually
be
marginally
more
power
efficient
than
the
tortoise
counter
to
theoretical
guidelines
Of
course
our
assumptions
are
not
realistic
In
particular
we
saw
earlier
Fig
that
is
quite
high
Hence
the
consumption
due
to
the
and
terms
in
Eqn
tilts
the
scales
back
in
favor
of
the
tortoise
The
final
validation
can
be
seen
in
Fig
where
we
plot
the
total
power
consumption
for
fixed
input
packet
rate
at
different
frequencies
These
are
the
first
set
of
results
in
this
section
where
we
include
idle
and
transition
times
Based
on
our
analysis
from
the
following
section
we
make
an
idle
core
enter
the
sleep
state
We
consider
and
cores
and
for
each
experiment
we
fix
the
input
packet
rate
to
be
the
maximum
rate
the
system
can
sustain
at
frequency
of
GHz
at
GHz
there
is
no
idle
time
and
this
corresponds
to
the
tortoise
strategy
the
tests
at
GHz
and
GHz
represent
the
fast
and
fastest
hare
strategy
It
is
clear
from
the
figure
that
the
configuration
with
the
lowest
frequency
is
always
the
most
energy
efficient
Hence
in
summary
the
tortoise
wins
in
keeping
with
what
the
theoretical
power
model
would
suggest
However
this
is
not
because
the
work
is
more
efficiently
processed
at
low
frequency
as
the
power
models
would
indicate
but
because
being
idle
is
not
sufficiently
efficient
the
terms
and
are
quite
significant
From
Fig
we
can
also
derive
the
additional
energy
cost
the
hare
incurs
For
example
looking
at
offered
load
of
Mpps
the
hare
is
using
packet
That
is
more
than
at
the
maximum
rate
where
there
are
no
idle
periods
and
it
only
needs
per
packet
Thus
packet
is
the
energy
penalty
of
following
hare
strategy
The
penalty
of
being
tortoise
is
instead
packet
XX
packet
Therefore
to
make
the
hare
win
on
the
tortoise
system
designers
would
need
to
reduce
the
term
by
about
XX
compared
to
today's
system
this
number
is
consistent
across
the
range
of
offered
load
in
Fig
Until
then
the
tortoise
will
be
hard
to
beat
don't
know
how
to
close
this
paragraph
Multiple
cores
We
now
consider
the
case
where
we
have
cores
to
as
before
process
packets
in
time
The
results
in
the
previous
section
show
that
it
is
more
energy
efficient
to
run
an
individual
core
at
low
frequency
and
minimize
idle
time
Applying
this
to
the
multiple
cores
case
would
mean
dividing
the
work
the
incoming
packets
across
multiple
cores
such
that
each
core
runs
at
frequency
at
which
it
is
fully
utilized
no
idle
time
In
doing
so
however
we
must
decide
whether
to
divide
the
work
across
fewer
cores
running
at
relatively
higher
frequency
or
more
cores
at
low
frequency
Again
we
first
look
to
theoretical
models
to
understand
potential
trade
offs
Let
us
assume
that
single
core
at
frequency
can
process
exactly
packets
in
time
Then
our
design
choice
is
between
strength
in
speed
use
cores
at
frequency
Each
core
processes
packets
sees
no
idle
time
and
hence
consumes
energy
strength
in
numbers
use
cores
at
frequency
Each
core
now
processes
packets
sees
no
idle
time
and
hence
consumes
energy
As
before
an
idealized
model
gives
since
cores
at
process
th
the
number
of
packets
at
th
the
speed
and
hence
our
comparison
is
between
and
If
the
active
power
grows
faster
than
as
the
theory
suggests
then
the
strength
in
numbers
approach
is
clearly
more
energy
efficient
This
points
us
towards
running
with
the
maximum
number
of
cores
each
running
at
the
minimum
frequency
required
to
sustain
the
incoming
traffic
Looking
for
empirical
validation
we
consider
again
the
packets
forwarded
per
Joule
but
now
comparing
two
sets
of
configurations
one
with
cores
running
at
frequency
and
one
with
cores
at
frequency
Unfortunately
since
our
hardware
offers
frequency
range
between
we
can
only
derive
data
points
for
and
the
corresponding
results
are
shown
in
Fig
From
the
figure
we
see
that
the
empirical
results
do
indeed
match
the
theoretical
guidelines
However
the
limited
range
of
frequencies
available
in
practice
might
raise
the
question
of
whether
we
can
expect
this
guideline
to
hold
in
general
That
is
what
can
we
expect
from
cores
at
frequency
vs
cores
at
frequency
where
and
To
answer
this
we
run
an
exhaustive
experiment
measuring
power
consumption
for
all
possible
combinations
of
number
of
cores
and
core
frequency
The
results
are
shown
in
Fig
for
each
combination
we
measure
the
power
consumption
shown
on
the
axis
and
maximum
forwarding
rate
axis
that
the
cores
can
sustain
at
frequency
Thus
in
all
test
scenarios
the
cores
in
question
are
fully
utilized
with
no
idle
times
We
see
that
for
any
given
packet
rate
it
is
always
better
to
run
more
cores
at
lower
frequency
validating
that
strength
in
numbers
is
the
preferred
approach
to
exploiting
multiple
cores
Applying
this
strategy
under
the
practical
constraints
of
real
server
system
however
raises
one
additional
problem
naive
interpretation
of
the
strength
in
numbers
strategy
would
be
to
simply
turn
on
all
available
cores
and
then
crank
up
down
the
frequency
based
on
the
input
rate
without
ever
worrying
about
how
many
cores
to
turn
on
This
would
be
reasonable
if
we
could
tune
frequencies
at
will
starting
from
close
to
GHz
However
as
mentioned
the
frequency
range
available
to
us
starts
at
GHz
and
so
far
we've
only
considered
the
efficiency
of
cores
that
run
fully
utilized
at
any
frequency
For
example
if
we
consider
the
core
case
in
Fig
we
only
see
the
power
consumption
for
data
rates
higher
than
approx
Mpps
the
max
forwarding
rate
at
GHz
How
would
cores
fare
at
lower
packet
rates
Before
answering
this
question
we
must
first
decide
how
to
operate
cores
that
are
under
utilized
even
at
their
lowest
operating
frequency
The
only
option
for
such
cores
is
to
use
sleep
states
and
our
question
comes
down
to
which
of
the
three
sleep
states
or
is
best
The
answer
to
this
depends
on
the
power
savings
vs
transition
latency
associated
with
each
state
We
empirically
measured
the
idle
power
consumption
and
average
transition
exit
latency
for
each
state
the
results
are
shown
in
Table
We
see
that
and
offer
only
modest
savings
compared
to
but
incur
quite
large
transition
times
This
suggests
that
offers
the
sweet
spot
in
the
tradeoff
The
choice
of
one
state
instead
of
another
will
affect
three
parameters
in
equation
the
power
consumed
to
enter
or
exit
the
sleep
state
the
time
to
transition
or
exit
latency
and
the
idle
power
of
the
system
In
order
to
precisely
quantify
the
contribution
of
each
term
we
first
determine
the
power
usage
of
the
various
states
Fig
then
we
measure
their
exit
latencies
Fig
and
finally
the
power
usage
of
the
system
under
low
load
and
with
cores
that
attempt
to
transition
to
or
Fig
Fig
shows
that
with
all
cores
in
the
system
can
shed
an
additional
compared
to
keeping
all
cores
in
When
all
cores
are
in
the
system
power
usage
is
down
to
that
is
of
the
power
consumed
when
all
the
cores
are
in
These
power
savings
are
evenly
distributed
across
cores
To
estimate
the
exit
latencies
we
measure
the
delay
of
packets
through
software
router
driven
by
traffic
at
very
low
packet
rate
packet
sec
When
an
interrupt
arrives
the
core
must
first
exit
from
its
state
depending
on
the
experiment
and
then
packet
processing
can
begin
Due
to
the
low
packet
rate
cores
have
plenty
of
time
to
return
to
deep
power
down
state
before
the
next
interrupt
Fig
plots
the
packet
delay
minimum
maximum
average
depending
on
the
state
The
forwarding
latencies
in
and
are
practically
the
same
This
validates
that
the
exit
latency
from
is
comparable
to
cache
miss
Waking
up
from
deep
power
down
state
instead
requires
longer
time
for
and
about
for
To
verify
this
we
measured
the
power
consumption
under
increasing
input
packet
rates
using
fixed
number
of
cores
running
at
fixed
frequency
We
do
three
set
of
experiments
corresponding
to
whether
an
under
utilized
core
enters
or
Fig
shows
the
results
for
and
cores
and
frequency
of
GHz
We
see
that
which
state
we
use
has
very
little
impact
on
the
total
power
consumption
of
the
system
This
is
because
even
at
low
packet
rates
the
packet
interarrival
times
are
low
enough
Mpps
implies
packet
every
that
cores
have
few
opportunities
to
transition
to
or
In
summary
given
its
low
transition
time
is
the
best
choice
for
an
under
utilized
core
large
exit
latency
is
potentially
problematic
if
it
causes
packets
to
be
dropped
At
line
rate
the
exit
latency
of
translates
into
packets
that
need
to
be
buffered
by
the
NIC
The
network
interfaces
used
in
our
system
fairly
typical
of
high
speed
NICs
have
receive
queues
that
can
accommodate
up
to
packets
which
is
almost
three
times
the
capacity
required
in
the
worst
case
scenario
core
in
Thus
putting
cores
to
sleep
and
waking
them
up
to
process
incoming
packets
introduces
small
additional
latency
but
is
not
likely
to
cause
packet
drops
To
make
this
choice
we
plot
in
Fig
the
energy
usage
per
packet
when
the
cores
run
at
the
lowest
frequency
and
transition
to
the
three
states
when
there
is
no
traffic
to
process
As
we
can
see
from
the
figure
there
is
very
little
advantage
in
using
deep
power
down
states
like
or
This
is
because
even
if
the
packet
rate
is
low
the
time
it
takes
to
transition
to
or
is
still
longer
than
the
time
interarrival
between
packets
Hence
we
choose
to
use
to
avoid
the
exit
latency
penalty
of
the
other
states
Now
that
we
know
what
an
under
utilized
core
should
do
we
extend
the
results
from
Fig
by
lowering
the
input
data
rates
to
consider
the
case
of
under
utilized
cores
For
clarity
in
Fig
we
plot
only
subset
of
the
data
points
We
see
that
for
any
packet
rate
the
appropriate
strategy
is
not
to
run
with
the
maximum
cores
at
the
lowest
frequency
but
rather
to
run
with
the
maximum
cores
that
can
be
kept
fully
utilized
For
example
at
Mpps
the
configuration
with
active
cores
saves
in
excess
of
compared
to
the
cores
configuration
In
summary
our
study
reveals
three
key
guidelines
that
maximize
power
savings
strength
in
numbers
the
aggregate
input
workload
should
be
equally
divided
between
the
maximum
number
of
cores
that
can
be
kept
fully
utilized
when
processing
their
share
of
the
workload
act
like
tortoise
each
core
should
run
at
the
lowest
possible
frequency
required
to
keep
up
with
its
input
workload
as
opposed
to
running
at
higher
frequencies
and
then
going
to
sleep
take
quick
light
naps
if
single
core
running
at
its
lowest
possible
frequency
is
under
utilized
it
should
enter
the
lightest
sleep
state
as
opposed
to
deeper
sleep
states
Following
the
above
guidelines
leads
to
the
lower
envelope
of
the
curves
in
Fig
which
represents
the
optimal
power
consumption
at
any
given
packet
rate
In
the
following
section
we
describe
how
we
combine
these
guidelines
into
practical
algorithm
Implementation
Our
empirical
results
tell
us
that
strategy
that
yields
the
maximum
power
saving
is
one
that
tracks
the
lower
envelope
of
the
curves
in
Figure
simple
implementation
of
that
strategy
could
be
to
use
lookup
table
that
for
any
input
data
rate
returns
the
optimal
configuration
in
terms
of
number
of
cores
and
frequencies
However
such
an
approach
has
two
limitations
First
to
work
as
promised
it
requires
perfect
knowledge
of
the
instantaneous
data
rate
Second
any
change
in
the
hardware
new
processor
with
more
cores
or
wider
range
of
operating
frequencies
would
require
comprehensive
benchmarking
to
recompute
the
entire
table
for
all
possible
configurations
An
alternative
is
to
devise
an
algorithm
that
while
adhering
to
the
guidelines
of
the
previous
section
tries
to
approximate
the
lower
envelope
of
the
curves
with
no
explicit
knowledge
of
those
curves
An
approach
that
maps
quite
well
to
the
guidelines
is
the
following
iterative
algorithm
that
we
will
call
PowerSave
Start
with
only
one
core
active
at
the
minimum
frequency
All
other
cores
are
in
deep
power
down
state
inactive
The
NIC
is
instructed
to
send
packets
only
to
the
one
active
core
As
the
load
increases
beyond
what
the
active
core
can
sustain
wake
up
one
more
core
and
split
the
traffic
evenly
among
all
active
cores
If
all
cores
are
active
increase
the
frequency
of
all
cores
to
keep
up
with
the
input
data
rate
If
traffic
load
decreases
first
lower
the
frequency
of
all
cores
and
then
start
turning
off
one
core
at
time
consolidating
traffic
onto
the
remaining
active
cores
To
understand
how
well
this
algorithm
could
approximate
the
optimal
power
curve
we
emulate
its
behavior
by
using
the
power
measurement
used
to
plot
Figure
In
Figure
we
show
the
power
usage
for
an
optimal
algorithm
one
that
follows
the
lower
envelope
of
Figure
and
for
our
approximated
power
saving
algorithm
The
approximation
closely
tracks
the
optimal
algorithm
At
very
low
rate
our
algorithm
chooses
to
turn
two
cores
on
much
earlier
than
the
optimal
solution
would
Even
so
the
additional
power
consumption
is
very
small
below
given
that
the
two
cores
always
run
at
the
lowest
frequency
Turning
this
algorithm
into
an
actual
implementation
requires
two
mechanisms
way
of
determining
whether
the
current
number
of
cores
and
frequency
is
the
minimum
required
to
sustain
the
input
rate
and
way
of
diverting
traffic
across
more
cores
or
consolidating
traffic
onto
fewer
cores
The
remainder
of
this
section
describes
our
implementation
of
the
two
mechanisms
Online
adaptation
algorithm
The
goal
of
the
adaptation
algorithm
is
to
determine
if
the
current
configuration
is
the
minimum
configuration
that
can
sustain
the
input
traffic
rate
The
algorithm
needs
to
be
able
to
quickly
adapt
to
changes
in
the
traffic
load
and
do
so
with
as
little
overhead
as
possible
good
indicator
of
whether
the
traffic
load
is
too
high
or
low
for
the
current
configuration
is
the
number
of
packets
in
the
NIC's
queues
Obtaining
the
queue
length
from
the
NICs
incurs
very
little
overhead
as
that
information
is
kept
in
one
of
the
NIC's
memory
mapped
registers
If
the
queues
are
empty
and
stay
empty
for
while
we
can
assume
that
too
many
cores
are
assigned
to
process
the
incoming
packets
If
the
queues
are
filling
up
instead
we
can
assume
that
more
cores
or
higher
frequency
are
needed
to
process
the
incoming
packets
This
load
estimation
is
run
as
part
of
the
interrupt
handler
to
allow
for
quick
response
to
rate
changes
Only
one
core
per
interface
needs
to
run
this
estimator
to
decide
when
to
wake
up
or
put
to
sleep
the
other
cores
We
set
two
queue
thresholds
for
hysteresis
and
when
the
number
of
packets
is
below
above
threshold
for
given
number
of
samples
we
turn
off
turn
on
one
core
The
pseudocode
of
the
algorithm
is
the
following
The
parameters
and
are
used
to
set
the
target
queue
occupancy
for
each
receive
queue
Setting
low
queue
thresholds
leads
to
smaller
queueing
delays
at
cost
of
higher
power
usage
The
choice
of
the
most
appropriate
thresholds
is
best
left
to
network
operators
they
can
trade
average
packet
latency
for
power
usage
In
our
experiments
we
set
and
for
target
queueing
delay
of
assuming
core
can
forward
at
Mpps
The
function
set
op
sets
the
operating
point
cores
frequency
to
one
of
the
supported
values
also
reprogramming
the
redirect
table
if
needed
The
parameter
UP
DOWN
tells
the
function
whether
to
wake
up
or
switch
off
core
or
increase
decrease
the
frequency
if
all
cores
are
already
active
The
variables
and
keep
track
of
how
many
times
the
queue
size
is
continuously
above
or
below
the
two
thresholds
If
the
queue
is
above
the
threshold
for
sufficient
time
the
system
is
under
heavy
load
and
adds
one
more
core
or
increases
the
frequency
if
all
cores
are
already
active
Note
that
every
time
we
change
the
operating
point
number
of
cores
or
frequency
the
counter
is
reset
to
give
the
system
sufficient
time
to
react
to
the
change
Conversely
if
we
are
under
the
threshold
for
sufficient
time
we
decrease
the
frequency
or
turn
off
one
core
if
the
frequency
is
already
at
the
minimum
Once
again
the
counter
is
reset
after
shift
to
give
the
system
time
to
react
After
adjusting
the
operating
level
we
process
batch
of
packets
and
either
repeat
the
loop
or
halt
thus
moving
to
state
if
there
are
no
more
packets
to
be
processed
In
case
of
halt
the
next
interrupt
will
resume
processing
with
no
further
delays
other
than
those
related
to
interrupt
generation
and
dispatching
Assigning
queues
to
cores
dynamically
Our
algorithm
requires
that
the
NIC
be
able
to
split
the
incoming
traffic
evenly
between
variable
set
of
cores
For
this
we
use
the
support
for
multiple
input
and
output
queues
that
is
present
in
all
modern
NICs
The
mechanism
we
use
is
called
Receive
Side
Scaling
RSS
and
operates
as
follows
For
each
incoming
packet
the
NIC
computes
hash
function
on
the
five
tuple
source
and
destination
IP
source
and
destination
port
and
protocol
number
of
the
packets
The
least
significant
bits
of
the
hash
are
used
as
an
index
into
redirect
table
This
table
holds
entries
that
contain
the
number
of
the
queue
to
be
used
for
packets
with
that
hash
as
shown
in
Figure
When
packet
is
placed
in
its
corresponding
queue
an
interrupt
is
raised
Each
queue
has
dedicated
interrupt
that
we
can
program
to
be
directed
to
any
core
The
number
of
queues
on
NIC
can
only
be
set
at
startup
Any
change
in
the
number
requires
reset
of
the
card
For
this
reason
we
statically
assign
queues
to
cores
as
we
start
Click
To
make
sure
inactive
cores
do
not
receive
traffic
we
modify
the
redirect
table
by
mapping
entries
to
queues
that
have
been
assigned
to
active
cores
We
always
keep
the
entries
in
the
table
well
balanced
so
that
traffic
is
spread
evenly
across
cores
that
are
active
and
processing
packets
The
table
is
only
bytes
long
so
modifications
are
relatively
fast
and
cheap
considering
that
we
do
not
modify
it
too
often
If
core
does
not
receive
traffic
on
its
queue
it
remains
in
deep
power
down
When
additional
cores
are
needed
to
process
traffic
we
reconfigure
the
redirect
table
to
include
the
additional
queue
The
update
to
the
redirect
table
has
almost
immediate
effect
this
is
important
because
it
immediately
reduces
the
load
on
the
active
cores
As
soon
as
the
first
packets
arrives
to
the
new
queue
the
interrupt
wakes
up
the
corresponding
core
which
eventually
after
the
exit
latency
starts
processing
the
traffic
Taking
out
core
is
equally
simple
we
reprogram
the
redirect
table
so
that
no
new
packets
will
reach
the
extra
core
Also
we
instruct
the
core
to
enter
state
on
halt
instead
of
Eventually
the
queue
will
become
empty
and
the
core
will
enter
from
which
it
does
not
exit
until
the
queue
is
enabled
again
Finally
we
note
that
redirecting
traffic
to
new
queues
may
introduce
additional
packet
processing
latency
In
current
NICs
dispatching
packets
to
the
new
queue
happens
almost
immediately
and
the
incoming
packet
rate
on
each
queue
decreases
accordingly
The
drawback
is
that
any
packet
in
the
newly
enabled
queue
will
not
be
processed
before
the
or
so
needed
to
bring
core
in
back
to
Whether
this
extra
latency
is
acceptable
or
not
depends
on
the
delay
currently
experienced
by
packets
belonging
to
the
same
flow
This
delay
is
equal
to
the
current
queue
length
divided
by
the
number
of
packets
per
second
that
core
can
process
In
our
system
the
value
of
ranges
between
and
packets
when
the
control
algorithm
kicks
in
and
activates
an
additional
core
The
rate
is
in
the
range
of
to
Mpps
The
resulting
packet
latency
between
and
ms
is
in
the
same
range
of
the
time
to
exit
from
which
removes
the
need
to
use
sophisticated
strategies
to
re
duce
this
latency
To
cope
with
the
differences
in
traffic
load
on
the
different
interfaces
and
also
considering
the
throughput
of
the
cores
in
the
system
we
partition
cores
statically
across
interfaces
On
our
target
system
we
have
interfaces
and
total
of
cores
Thus
we
assigning
three
cores
to
each
interface
The
challenge
is
to
make
sure
that
changes
do
not
introduce
excessive
latency
while
at
the
same
time
make
an
efficient
use
of
energy
The
most
critical
issue
is
the
latency
to
exit
from
state
Ideally
we
could
keep
unused
cores
in
state
and
whenever
it
is
necessary
to
add
new
core
program
the
redirect
table
to
enable
the
corresponding
queue
so
that
the
forthcoming
interrupt
will
wake
up
the
core
and
start
operation
Dispatching
to
the
new
queue
happens
almost
immediately
so
the
incoming
packet
rate
on
each
queue
decreases
accordingly
The
drawback
is
that
any
packet
in
the
newly
enabled
queue
will
not
be
processed
before
the
or
so
needed
to
bring
the
core
back
to
Whether
this
extra
latency
is
acceptable
or
not
depends
on
the
delay
currently
experienced
by
packets
belonging
to
the
same
flow
which
equals
to
the
current
queue
length
divided
by
the
number
of
packets
per
second
that
core
can
process
In
our
system
the
value
of
ranges
between
and
packets
when
the
control
algorithm
kicks
in
and
activates
an
additional
core
The
rate
is
in
the
range
of
to
Mpps
The
resulting
packet
latency
between
and
ms
is
in
the
same
range
of
the
time
to
exit
from
which
removes
the
need
to
use
sophisticated
strategies
to
reduce
this
latency
Moving
to
lower
power
level
involves
again
change
of
frequency
and
possibly
also
reprogramming
the
redirect
table
to
stop
dispatching
traffic
to
one
of
the
queues
As
before
frequency
changes
are
almost
instantaneous
and
have
no
particular
impact
on
the
system
other
than
change
in
performance
Reprogramming
the
redirect
table
is
also
instantaneous
the
side
effect
being
that
flows
formerly
on
the
disabled
queue
will
now
be
spread
over
the
the
remaining
queues
Evaluation
To
evaluate
the
performance
of
our
prototype
router
in
realistic
setting
we
generate
traffic
using
two
packet
traces
the
Abilene
trace
collected
on
the
Abilene
network
and
one
day
long
trace
from
the
Patents
dataset
collected
in
small
enterprise
Gbps
network
The
former
contains
only
packet
headers
while
the
latter
includes
packet
payloads
as
well
Our
generator
software
is
composed
of
many
traffic
sources
each
reading
from
copy
of
the
original
traces
By
mixing
multiple
traffic
sources
we
can
generate
high
bit
rates
as
well
as
introduce
burstiness
and
sudden
spikes
in
the
traffic
load
This
helps
in
testing
the
responsiveness
and
stability
of
our
power
saving
algorithm
We
are
interested
in
evaluating
the
performance
of
our
system
with
broad
range
of
applications
To
this
end
we
run
experiments
with
the
following
packet
processing
applications
IPv
routing
Netflow
like
monitoring
application
that
maintains
per
flow
state
an
IPSEC
implementation
that
encrypts
every
packet
using
AES
and
the
Redundancy
Elimination
implementation
from
which
removes
duplicate
content
from
the
traffic
Note
that
we
use
all
applications
as
is
without
modifications
from
their
original
Click
based
implementations
This
set
of
applications
is
quite
representative
of
typical
networking
applications
Routing
is
state
less
application
where
each
packet
can
be
processed
independently
of
the
other
Netflow
is
stateful
and
requires
to
create
and
maintain
large
amount
of
per
flow
state
IPSEC
is
very
CPU
intensive
but
stateless
Finally
Redundancy
Elimination
is
both
stateful
keeps
information
about
previously
observed
packets
and
CPU
intensive
to
find
duplicate
content
in
packet
payloads
We
generate
similar
input
traffic
profiles
for
all
applications
Figure
shows
the
traffic
load
over
time
for
the
different
applications
We
tune
the
traffic
profiles
so
that
the
average
utilization
of
the
router
over
the
duration
of
the
experiment
is
around
This
results
in
different
bit
rates
for
different
applications
as
they
differ
in
per
packet
processing
cost
with
Redundancy
Elimination
being
the
most
demanding
The
load
is
evenly
distributed
across
the
four
interfaces
and
the
routing
table
is
uniform
so
that
no
output
interface
has
to
forward
more
than
the
Gbps
it
can
handle
All
the
traffic
sources
are
activated
in
less
than
one
second
This
way
we
can
validate
that
the
adaptation
algorithm
can
quickly
respond
to
abrupt
changes
in
traffic
demands
We
measure
the
overall
energy
used
by
our
system
varying
the
input
traffic
rate
from
to
Gbps
across
the
four
interfaces
Figure
shows
how
the
traffic
varies
over
time
for
each
application
In
the
five
minutes
of
the
experiments
we
vary
the
utilization
of
the
links
from
to
with
average
utilization
The
routing
table
is
uniform
so
that
no
output
interface
has
to
forward
more
than
the
Gbps
it
can
handle
At
time
we
increase
the
total
bit
rate
from
Gbps
to
Gbps
in
less
than
one
second
This
way
we
can
validate
that
the
adaptation
algorithm
can
quickly
respond
to
abrupt
changes
in
traffic
demands
The
AES
encryption
is
entirely
implemented
in
software
with
no
hardware
support
and
is
applied
to
every
packet
the
router
sends
For
this
very
CPU
intensive
workload
we
send
an
input
rate
with
the
same
profile
but
with
lower
rate
to
accommodate
for
the
extra
per
packet
processing
The
average
rate
is
again
chosen
to
be
of
the
maximum
rate
our
router
can
sustain
same
consideration
for
RE
We
first
focus
on
the
power
consumption
of
the
various
applications
and
then
measure
the
impact
of
PowerSave
on
more
traditional
performance
metrics
such
as
latency
drops
and
packet
reordering
Power
consumption
Figure
shows
the
power
consumption
over
time
for
the
four
applications
under
study
In
the
figures
we
compare
the
power
consumption
of
the
default
Click
implementation
the
NAPI
Click
and
Click
with
PowerSave
As
expected
unmodified
Click
fares
the
worst
with
power
consumption
hovering
around
for
all
applications
at
all
traffic
rates
The
power
usage
with
NAPI
Click
and
PowerSave
instead
tracks
to
varying
degree
the
input
traffic
rate
PowerSave
is
consistently
the
most
energy
efficient
at
all
rates
for
all
applications
The
advantage
of
PowerSave
is
more
prominent
when
the
load
is
fairly
low
as
that
is
when
consolidating
the
work
across
cores
yields
the
maximum
benefits
Over
the
duration
of
the
experiments
PowerSave
yields
an
overall
energy
saving
between
and
compared
to
NAPI
Click
and
compared
to
unmodified
Click
The
plots
in
Figure
show
the
power
usage
over
time
for
different
software
frameworks
for
each
application
we
consider
As
reference
point
we
show
the
high
and
almost
flat
power
curve
for
the
unmodified
Click
stack
Default
Click
indeed
uses
polling
approach
to
read
incoming
packets
consuming
all
the
idle
CPU
cycles
We
found
the
power
consumption
for
such
solution
to
depend
loosely
from
both
the
incoming
rate
and
the
application
we
measured
an
average
of
for
packet
encryption
and
only
less
for
the
other
workloads
NAPI
support
creates
sleep
opportunities
for
individual
cores
whenever
all
the
packets
in
the
input
queue
are
processed
The
power
curve
more
closely
tracks
the
traffic
curve
however
incoming
packets
are
still
divided
among
all
the
available
cores
and
they
run
at
their
maximum
frequency
going
to
the
deepest
sleep
state
whenever
possible
following
the
race
to
idle
strategy
It
can
be
seen
how
independently
from
the
application
our
power
saving
strategy
uses
less
power
than
other
solutions
yielding
on
average
up
to
savings
when
compared
to
unmodified
Click
and
up
to
with
respect
to
the
NAPI
solution
When
using
NetFlow
for
example
the
average
power
consumed
in
the
minutes
run
is
only
for
an
average
input
rate
of
Gbps
The
results
are
very
encouraging
giving
us
an
idea
of
how
the
router
will
perform
on
wide
range
of
applications
Traditional
performance
metrics
We
turn
our
attention
to
other
metrics
beyond
power
consumption
namely
packet
loss
latency
and
reordering
Our
algorithm
may
introduce
loss
or
high
latency
by
turning
on
cores
too
slowly
in
the
face
of
varying
traffic
demands
Reordering
may
be
introduced
when
packets
belonging
to
the
same
flow
are
redirected
to
different
core
Regarding
packet
losses
the
PowerSave
algorithm
reacts
quickly
enough
to
avoid
packet
drops
Indeed
no
packet
losses
were
observed
in
any
of
our
experiments
We
also
measured
the
latency
of
packets
traversing
the
router
Figure
plots
the
average
minimum
and
th
percentile
over
each
interval
we
collect
latency
sample
every
ms
In
the
interest
of
space
we
only
plot
results
for
one
PowerSave
experiment
with
IPv
Routing
Other
experiments
show
similar
behavior


The
average
latency
hovers
in
the
range
The
same
experiments
with
Click
unmodified
yield
an
average
latency
of
The
th
percentile
of
the
latency
is
up
to
times
the
average
latency
it
peaks
at
Some
of
the
peaks
are
unavoidable
since
waking
up
core
on
from
may
introduce
latency
of
up
to
However
that
is
limited
to
the
first
packet
that
reaches
the
queue
handled
by
that
core
As
last
performance
metric
we
also
measured
packet
reordering
In
our
system
reordering
can
only
occur
when
traffic
is
diverted
to
new
queue
Hence
two
back
to
back
packets
and
belonging
to
the
same
flow
may
be
split
across
two
queues
and
incur
very
different
latency
Given
that
new
queues
are
activated
only
when
the
current
ones
start
to
fill
up
it
is
possible
to
have
packet
at
the
back
of
one
queue
while
packet
is
first
in
line
to
be
served
on
the
new
queue
On
the
other
hand
packets
in
the
newly
activated
queue
will
not
be
processed
until
the
core
assigned
to
it
exits
state
Given
that
in
our
setting
the
adaptation
algorithm
aims
for
of
queueing
delay
it
is
quite
likely
that
packet
will
be
served
while
the
new
core
is
still
exiting
We
confirmed
this
conjecture
in
our
experiments
We
have
measured
zero
packets
being
reordered
To
consider
an
extreme
case
of
very
high
bandwidth
flows
we
even
measured
reordering
of
all
packets
independently
of
the
flow
they
belong
to
and
still
found
none
Impact
of
traffic
burstiness
Our
results
so
far
were
based
on
input
traffic
whose
fine
grained
burstiness
over
short
timescales
derived
from
the
natural
variability
associated
with
software
based
traffic
source
and
multiplexing
traffic
from
multiple
such
sources
To
study
the
impact
of
fine
grained
burstiness
in
more
controlled
manner
we
modified
the
traffic
sources
to
generate
traffic
following
an
on
off
pattern
During
an
on
period
the
traffic
source
generates
burst
of
back
to
back
packets
at
the
maximum
rate
We
thus
control
the
burstiness
of
the
traffic
by
picking
the
length
of
the
on
period
the
number
of
back
to
back
packets
while
keeping
the
average
packet
rate
constant
Fig
shows
the
power
usage
of
our
system
as
we
vary
the
burstiness
of
the
sources
value
of
corresponds
to
uniform
traffic
The
average
traffic
rate
is
around
Gbps
per
interface
In
the
interest
of
space
we
only
plot
the
results
for
IPv
Routing
Other
applications
exhibit
similar
behavior
As
we
can
see
the
power
usage
varies
very
little
as
we
increase
the
burstiness
This
shows
that
the
controller
is
stable
enough
to
make
sure
large
short
term
burstiness
does
not
impact
its
performance
As
expected
the
power
usage
with
unmodified
Click
is
flat
while
NAPI
Click
benefits
from
traffic
burstiness
as
interrupts
are
spaced
out
more
with
burstier
traffic
However
for
all
levels
of
burstiness
PowerSave
is
clearly
the
most
energy
efficient
We
measured
also
latency
and
packet
loss
and
saw
similar
results
where
burstiness
has
little
or
no
impact
We
refer
the
reader
to
for
detailed
analysis
of
the
latency
results
with
bursty
traffic
Traditional
performance
metrics
In
addition
to
energy
usage
we
measured
the
impact
of
the
power
saving
on
the
more
traditional
router
performance
metrics
packet
drops
latency
and
reordering
No
packet
losses
were
observed
in
any
of
our
experiments
The
adaption
algorithm
is
capable
of
reacting
to
increases
in
the
input
rate
quickly
enough
to
avoid
drops
We
also
measured
the
latency
of
packets
traversing
the
router
Figure
plots
the
average
minimum
and
th
percentile


on
each
interval
we
collect
latency
sample
every
ms
The
average
latency
hovers
around
This
is
in
line
with
our
expectations
Indeed
in
this
experiments
we
set
the
high
threshold
in
the
algorithm
at
packets
Assuming
single
core
can
process
Mpps
that
translate
in
target
maximum
latency
of
The
algorithm
is
therefore
capable
of
keeping
the
average
latency
close
to
target
For
comparison
we
ran
the
same
set
of
experiments
with
Click
unmodified
Click
yields
an
average
latency
of
In
summary
we
pay
price
of
in
latency
for
power
saving
The
th
percentile
of
the
latency
is
up
to
times
the
average
latency
it
peaks
at
Some
of
the
peaks
are
unavoidable
Turning
core
on
from
introduces
an
average
latency
of
about
However
that
is
only
for
the
first
packets
that
reach
the
queue
handled
by
that
core
That
is
enough
to
move
the
th
percentile
curve
but
not
the
average
delay
However
the
spikes
in
the
th
percentile
are
more
frequent
than
we
expected
We
conjecture
that
this
is
driven
by
two
factors
First
Linux
is
not
real
time
operating
systems
and
Click
threads
may
be
scheduled
out
leading
to
additional
latency
Both
these
events
may
lead
to
queues
building
up
thus
forcing
the
adaptation
algorithm
to
turn
additional
queues
on
when
there
is
no
real
need
We
ran
separate
set
of
experiments
using
the
unmodified
Click
code
base
with
the
same
input
traffic
With
Click
unmodified
the
average
latency
was
The
additional
latency
with
the
power
saving
algorithm
is
not
surprising
The
packet
latency
is
driven
by
our
target
for
queue
occupancy
ql
in
the
pseudocode
in
Section
In
our
experiments
we
set
ql
to
be
packets
Given
that
single
core
can
process
at
most
Mpps
it
means
that
the
algorithm
will
enable
an
additional
core
only
if
the
queueing
delay
exceeds
Setting
lower
threshold
would
lead
to
more
cores
processing
traffic
and
higher
average
power
usage
However
the
choice
of
the
threshold
is
best
left
to
network
operators
they
can
trade
additional
latency
for
lower
power
usage
As
last
performance
metric
we
also
measured
packet
reordering
In
our
system
reordering
can
only
occur
when
traffic
is
diverted
to
new
queue
Hence
two
back
to
back
packets
and
belonging
to
the
same
flow
may
be
split
across
two
queues
and
incur
very
different
latency
Given
that
new
queues
are
activated
only
when
the
current
ones
start
to
fill
up
it
is
possible
to
have
packet
at
the
back
of
one
queue
while
packet
is
first
in
line
to
be
served
on
the
new
queue
On
the
other
hand
packets
in
the
newly
activated
queue
will
not
be
processed
until
the
core
assigned
to
it
exits
state
in
about
Given
that
in
our
setting
the
adaptation
algorithm
aims
for
latency
of
about
it
is
quite
likely
that
packet
will
be
served
while
the
new
cores
is
still
exiting
We
confirmed
this
conjecture
in
our
experiments
We
have
measured
zero
packets
being
reordered
To
consider
an
extreme
case
of
very
high
bandwidth
flows
we
even
measured
reordering
of
all
packets
independently
of
the
flow
they
belong
to
and
still
found
none
Encryption
performance
different
packet
processing
application
may
change
the
behavior
of
the
system
in
ways
we
did
not
take
into
account
in
our
energy
efficient
design
To
explore
this
possibility
we
added
to
our
router
configuration
an
IPSEC
element
that
encrypts
with
AES
the
payload
of
every
packet
it
sends
This
setup
allows
us
to
emulate
the
behavior
of
VPN
gateway
for
example
The
AES
encryption
is
entirely
implemented
in
software
with
no
hardware
support
Thus
as
very
CPU
intensive
workload
it
may
alter
the
power
behavior
of
the
system
we
studied
in
Section
We
send
an
input
rate
with
the
same
profile
of
Figure
but
with
lower
rate
to
accommodate
for
the
extra
per
packet
processing
The
average
rate
during
the
experiment
is
again
chosen
to
be
of
the
maximum
rate
our
router
can
sustain
The
average
power
with
encryption
is
savings
compared
to
Click
The
results
with
packet
encryption
though
very
encouraging
still
do
not
give
us
definitive
answer
on
how
the
router
would
perform
in
wide
range
of
applications
Packet
encryption
is
very
different
from
IP
routing
in
software
but
at
the
hardware
level
it
exercises
the
same
subsystems
of
the
CPU
even
though
to
much
higher
extent
there
are
still
no
floating
point
operations
and
very
limited
cache
coherency
traffic
Validating
our
low
power
strategies
on
much
wider
variety
of
applications
and
workloads
constitutes
major
part
of
our
future
work
Conclusion
We
tackle
the
problem
of
improving
the
power
efficiency
of
network
routers
without
compromising
their
performance
For
this
we
studied
the
power
vs
performance
tradeoffs
offered
by
different
approaches
to
low
power
operation
in
the
context
of
commodity
server
hardware
Our
study
reveals
three
guiding
principles
to
optimally
combine
different
hardware
power
management
options
Based
on
these
guidelines
we
build
prototype
Click
based
software
router
whose
power
consumption
grows
in
proportion
to
the
offered
load
using
between
and
of
the
original
power
without
compromising
on
peak
performance
Future
work
include
exploring
energy
efficiency
in
other
software
router
stacks
and
different
networking
applications
beyond
those
explored
here
We
are
also
interested
in
applying
the
same
design
principles
to
more
general
streaming
workloads
or
other
workloads
with
stringent
real
time
requirements
abbrv
tiny
theorem
Theorem
section
lemma
theorem
Lemma
definition
Definition
em
An
Energy
Case
for
Hybrid
Datacenters
em
First
Row
Second
Row
Intel
Research
Berkeley
University
of
California
at
Berkeley
University
of
Pisa
thebibliography
We
explore
the
potential
of
hybrid
designs
for
datacenter
environments
that
mixes
low
power
platforms
with
high
performance
ones
Our
approach
exploits
recent
advances
in
very
low
power
processor
designs
to
define
new
datacenter
architecture
that
can
deliver
energy
efficient
operations
without
sacrificing
performance
or
limiting
its
applicability
to
just
subset
of
datacenter
deployments
Through
empyrical
measurements
and
simulations
we
evaluate
the
feasibility
of
an
hybrid
approach
and
then
discuss
the
design
options
and
research
challenges
that
lie
ahead
Introduction
Energy
consumption
of
the
computing
infrastructure
has
become
major
concern
for
the
industry
and
society
at
large
Today's
datacenters
the
backbone
of
the
computing
infrastructure
are
limited
in
scale
by
the
costs
associated
with
power
distribution
cooling
density
Studies
estimate
that
power
related
costs
represent
already
almost
of
the
monthly
operating
cost
of
datacenter
and
those
costs
are
growing
much
faster
than
compute
related
costs
server
and
network
equipment
This
contributed
to
make
energy
efficiency
first
class
design
concern
at
all
levels
computation
and
data
processing
power
distribution
at
the
rack
and
server
level
power
generation
and
transmission
etc
Companies
such
as
Microsoft
and
Google
are
deploying
new
datacenters
near
cheap
power
sources
hydroelectric
power
stations
in
an
attempt
to
mitigate
energy
costs
Processor
manufacturers
are
pursuing
their
roadmap
of
multi
core
architectures
and
low
power
designs
The
research
community
has
also
proposed
power
efficient
designs
and
protocols
for
specific
workload
environments
office
environments
and
high
speed
networks
In
this
paper
we
look
at
one
specific
aspect
energy
efficient
clusters
for
large
datacenters
As
first
step
we
consider
the
current
trends
in
server
designs
and
try
to
exploit
them
to
our
advantage
Traditionally
power
efficient
designs
attempt
to
find
the
right
balance
between
two
distinct
and
often
conflicting
requirements
deliver
high
performance
at
peak
power
maximize
compute
capacity
for
given
power
budget
and
scale
power
consumption
with
load
energy
proportionality
and
very
low
power
operations
fundamental
challenge
in
finding
good
balance
is
that
when
it
comes
to
processor
design
the
mechanisms
that
satisfy
the
two
requirements
above
are
significantly
different
High
performance
requires
mechanisms
to
mask
memory
and
latencies
using
large
multi
level
caches
today's
server
processors
use
three
cache
levels
with
the
last
level
cache
projected
to
soon
reach
MB
large
translation
lookaside
buffers
out
of
order
execution
high
speed
buses
and
support
for
large
number
of
pending
memory
requests
This
mechanisms
result
in
large
transistor
counts
leading
to
high
leakage
power
and
overall
high
power
consumption
under
heavy
load
In
modern
processor
less
than
of
the
transistor
count
is
dedicated
to
the
actual
cores
Low
power
designs
on
the
other
hand
focus
only
on
those
processor
features
with
good
performance
watt
ratios
For
example
the
Atom
processor
includes
an
in
order
pipeline
that
can
execute
two
instructions
per
cycle
small
cache
and
power
efficient
clock
distribution
This
results
in
strongly
reduced
transistor
count
with
low
leakage
power
and
limited
power
consumption
at
very
low
load
Further
Atom
design
is
focused
on
allowing
quick
and
frequent
transitions
to
very
low
power
state
mW
with
less
than
exit
latency
Proposals
like
FAWN
and
Marlowe
exploit
these
features
to
build
arrays
of
low
power
servers
that
operate
efficiently
for
bound
workloads
In
summary
we
observe
dichotomy
between
low
power
and
high
performance
system
designs
Choosing
the
most
appropriate
design
for
power
efficient
data
center
architecture
is
far
from
straightforward
First
today's
datacenter
workloads
are
diverse
some
bound
map
reduce
like
lend
themselves
easily
to
low
power
designs
while
others
transactions
encryption
search
depend
on
high
performance
and
fast
response
times
to
satisfy
stringent
service
level
agreements
SLAs
Second
the
workload
dynamics
including
task
arrival
patterns
and
job
completion
times
may
completely
reverse
the
conclusion
of
static
workload
analysis
Finally
the
processor
is
just
one
contributor
to
the
overall
power
consumption
Other
system
components
such
as
the
motherboard
and
memory
controllers
DRAM
banks
and
power
supplies
contribute
to
large
fraction
of
the
overall
power
consumption
and
tend
not
to
be
optimized
for
low
power
operation
Given
these
challenges
we
propose
hybrid
solution
that
mixes
low
power
systems
and
high
performance
ones
We
first
perform
preliminary
evaluation
to
highlight
the
potential
of
hybrid
solutions
Then
in
Section
we
explore
the
design
options
in
this
space
giving
quick
overview
of
the
entire
spectrum
of
solutions
We
will
focus
on
understanding
the
challenges
in
two
extreme
points
in
the
spectrum
discrete
systems
high
performance
blade
next
to
low
power
blades
and
heterogeneous
multi
core
systems
with
single
instruction
set
Section
concludes
the
paper
with
summary
of
related
work
The
case
for
hybrid
approaches
As
first
step
we
are
interested
in
comparing
the
performance
of
different
systems
under
datacenter
like
workloads
For
this
task
we
consider
quad
core
dual
socket
Xeon
system
and
two
low
power
Atom
based
PCs
Table
summarizes
the
characteristics
of
the
three
systems
They
are
representative
of
high
performance
systems
currently
commonly
found
in
datacenters
and
low
power
platforms
that
have
been
proposed
as
way
to
build
energy
efficient
nettops
or
netbooks
Defined
the
platforms
we
need
to
pick
the
set
of
workloads
that
are
representative
of
large
datacenters
We
classify
workloads
in
three
broad
categories
Web
Services
this
is
the
classical
web
workload
to
serve
pages
to
users
The
data
requested
is
usually
small
object
in
large
dataset
an
item
on
sale
in
commerce
site
such
as
Amazon
The
first
request
may
lead
to
database
query
but
subsequent
requests
are
then
cached
in
memory
for
fast
retrieval
memcached
is
an
example
of
this
approach
for
large
clusters
and
currently
used
by
LiveJournal
Slashdot
Facebook
and
others
To
emulate
workload
that
imposes
heavy
load
on
the
memory
subsystem
we
use
the
standard
SPECweb
benchmark
Data
Mining
this
second
class
is
representative
of
large
scale
data
analysis
workloads
that
process
an
entire
dataset
in
distributed
fashion
This
is
typically
done
to
populate
the
reverse
index
used
in
search
engines
or
for
machine
learning
operations
to
drive
user
recommendation
engines
MapReduce
is
one
approach
used
to
distribute
the
computation
across
large
number
of
servers
in
the
datacenter
To
emulate
this
workload
we
use
Hadoop
an
open
source
MapReduce
implementation
with
pseudo
cluster
configuration
on
single
server
The
number
of
mappers
and
reducers
is
set
to
twice
the
number
of
cores
in
the
servers
this
setup
showed
the
best
performance
We
consider
two
applications
that
make
extensive
use
of
disk
and
are
available
in
the
standard
Hadoop
distribution
word
count
over
GB
of
data
and
sort
over
GB
of
data
Compute
Intensive
the
third
type
of
workloads
is
intended
to
model
applications
that
are
CPU
intensive
such
as
image
processing
or
video
encoding
They
may
operate
on
smaller
data
set
but
require
significant
amount
of
computation
for
each
data
object
To
emulate
this
class
of
workloads
on
datacenter
environment
we
use
the
Hadoop
pi
application
that
estimates
the
value
of
using
the
Monte
Carlo
method
and
use
ffmpeg
to
convert
file
from
Windows
Media
wmv
to
Flash
Video
flv
Performance
per
Watt
Figure
compares
the
performance
watt
of
the
three
platforms
over
the
various
workloads
The
performance
is
measured
as
the
rate
of
execution
one
over
total
execution
time
and
compared
to
the
power
consumption
of
the
platform
measured
at
the
wall
socket
To
easily
compare
the
workloads
in
one
graph
we
normalized
the
results
to
the
performance
watt
of
the
dual
core
Atom
system
few
observations
can
be
made
from
Figure
First
there
is
no
clear
winner
in
terms
of
performance
per
watt
Depending
on
workload
different
platforms
show
best
performance
per
watt
power
efficiency
This
suggests
that
mixing
different
platforms
can
be
better
in
terms
of
power
efficiency
with
diverse
workload
For
data
mining
workloads
bound
both
low
power
architectures
show
clear
advantage
Atom
is
better
than
Xeon
while
for
more
traditional
web
workloads
or
compute
intensive
one
the
Xeon
server
is
still
the
platform
of
choice
Further
the
least
power
hungry
architectures
the
Atom
exhibit
the
best
performance
watt
for
WordCount
compared
to
the
other
servers
but
very
little
gain
in
performance
watt
compared
to
Xeon
processors
for
other
workloads
This
is
due
to
the
specific
mini
PCI
solid
state
drive
SSD
used
in
the
system
that
provides
good
read
throughtput
but
very
low
write
throughput
WordCount
benefits
from
this
characterists
as
it
is
mainly
reads
with
very
little
data
written
back
to
disk
Note
that
in
these
graphs
we
are
still
not
taking
into
account
the
overall
execution
or
response
time
or
SLAs
We
will
consider
this
aspect
later
in
the
paper
when
we
discuss
temporal
characteristics
of
workload
Energy
Proportionality
Other
than
the
relative
performance
of
the
platforms
under
heavy
load
second
important
aspect
is
to
understand
how
power
consumption
scale
with
load
To
explore
this
further
we
used
the
SPECpower
standard
benchmark
that
can
issue
variable
number
of
transactions
to
test
the
platforms
under
various
load
levels
Figure
shows
the
power
consumption
as
function
of
the
number
of
transactions
per
second
To
compare
the
performance
over
the
entire
range
of
load
levels
we
consider
the
case
of
adding
more
Atom
based
PCs
to
handle
the
additional
load
thus
the
step
shape
of
the
Atom
curves
in
the
graph
We
can
make
two
main
observations
from
this
figure
First
from
the
experiments
we
can
see
how
set
of
Atom
based
platforms
could
be
used
to
mimic
energy
proportional
system
As
load
increases
the
aggregate
consumes
power
proportional
to
load
in
macro
level
Second
in
micro
level
both
platforms
in
isolation
show
quite
narrow
range
of
power
consumption
across
wide
range
of
load
levels
This
is
in
line
with
prior
work
that
indicate
that
other
system
components
not
the
CPU
are
responsible
for
the
poor
scaling
of
power
consumption
The
Atom
motherboards
we
used
in
this
test
comes
with
power
hungry
chipsets
the
consumption
when
idle
is
in
the
order
of
In
particular
the
memory
controller
Northbridge
is
three
year
old
design
built
with
nm
process
resulting
in
power
consumption
of
around
of
the
chipset
alone
More
recent
chipset
designs
GSE
manage
to
reduce
the
power
consumption
to
around
without
any
loss
of
features
for
datacenter
environments
Temporal
Characteristics
of
Workload
So
far
we
have
only
looked
at
performance
of
the
system
under
static
workload
ignoring
the
task
arrival
process
Reports
from
datacenter
operators
indicate
that
servers
run
between
and
of
their
maximum
utilization
levels
Servers
process
continuous
stream
of
task
requests
and
operators
try
to
distribute
evenly
across
the
data
center
to
avoid
high
loads
and
meet
latency
service
level
agreements
To
evaluate
the
potential
of
hybrid
solutions
we
create
simplified
model
of
task
arrivals
to
simulate
dynamic
workloads
and
derive
latency
and
power
consumption
over
time
of
several
design
options
We
generate
tasks
with
interarrival
times
derived
from
Pareto
distribution
with
shape
parameter
We
have
used
also
other
distributions
exponential
but
omit
results
from
this
paper
in
the
interest
of
space
To
model
the
computing
capabilities
of
the
low
power
and
high
performance
platforms
we
use
two
parameters
see
Table
number
of
threads
that
corresponds
to
the
number
of
tasks
requests
that
can
be
served
in
parallel
and
computing
capacity
that
corresponds
to
the
processing
time
of
each
task
normalized
to
Xeon
performance
The
actual
ratio
between
Xeon
and
Atom
is
derived
from
the
SPECpower
experimental
results


For
simplicity
in
this
synthetic
workload
we
assume
identical
tasks
that
require
constant
processing
time
Finally
the
power
consumption
is
computed
as
it
grows
linearly
between
the
minimum
idle
power
and
the
power
at
full
utilization
as
observed
experimentally
The
utilization
is
defined
as
the
ratio
between
the
number
of
active
tasks
and
the
number
of
threads
of
the
Xeon
platform
Figure
show
the
power
consumption
and
the
th
percentile
of
the
response
time
as
function
of
the
average
utilization
level
varied
using
the
scale
parameter
of
the
Pareto
distribution
of
the
task
interarrival
times
The
execution
time
is
normalized
to
the
execution
time
on
an
unloaded
Xeon
server
The
curves
labeled
Xeon
and
Atom
correspond
to
solutions
where
only
Xeon
or
Atom
platforms
are
used
As
expected
the
curves
follow
the
same
trend
as
in
Figure
for
power
consumption
while
response
times
grow
in
an
uncontrolled
fashion
as
the
load
approaches
The
remaining
three
curves
in
the
graphs
represent
three
possible
hybrid
solutions
using
both
one
Xeon
and
one
Atom
platform
The
lines
labelled
and
refer
to
solutions
that
implement
task
migration
from
the
Atom
to
Xeon
when
the
load
exceeds
the
capacity
of
the
Atom
platform
Specifically
when
the
number
of
concurrent
tasks
exceed
the
value
of
the
Atom
platform
wakes
up
the
Xeon
server
suspends
the
execution
of
the
tasks
and
migrate
them
to
Xeon
and
finally
goes
to
standby
state
During
the
execution
of
tasks
only
one
platform
is
running
and
the
consumption
of
the
other
is
given
by
Table
The
difference
between
and
is
only
in
the
time
required
to
migrate
tasks
and
to
wake
up
the
platforms
represents
the
ideal
case
where
both
migration
and
waking
up
is
instantenous
describes
another
extreme
where
the
time
to
wake
up
the
server
is
of
the
duration
of
the
task
and
the
migration
cost
is
equal
to
of
the
duration
of
the
task
Our
goal
here
is
not
to
design
specific
migration
strategy
but
rather
to
understand
the
performance
and
feasibility
of
such
solutions
We
can
expect
any
actual
solution
to
lie
within
the
two
extreme
shown
here
ideal
and
high
cost
The
last
solution
represents
the
case
where
there
is
no
migration
but
all
tasks
are
completed
on
the
same
platform
where
they
started
In
this
scenario
the
Atom
is
always
running
and
wakes
up
the
Xeon
only
when
the
number
of
concurrent
tasks
exceeds
This
mode
of
operation
is
akin
to
considering
the
Xeon
as
an
accelerator
board
for
the
Atom
platform
From
Figure
we
can
see
that
very
simple
hybrid
solution
even
with
just
one
Atom
and
one
Xeon
platform
achieve
good
energy
proportionality
Never
migrating
tasks
appears
to
be
feasible
strategy
that
leads
us
to
believe
that
very
simple
software
solutions
could
be
within
reach
In
Figure
we
plot
the
th
percentile
of
the
task
completion
time
task
runtime
plus
task
queueing
delay
Interestingly
and
show
latency
equal
to
the
minimum
Atom
latency
for
an
utilization
well
above
the
upper
limit
according
to
This
shows
that
if
running
task
on
an
unloaded
Atom
platforms
satisfies
datacenter
SLAs
then
hybrid
solutions
can
preserve
that
guarantee
However
not
all
hybrid
strategies
are
feasible
as
indicated
by
where
the
latency
is
dominated
by
the
large
migration
cost
and
wake
up
time
In
summary
we
have
shown
that
low
power
and
high
performance
platforms
exhibit
different
power
performance
based
on
the
workload
and
clearly
single
solution
cannot
satisfied
the
wide
range
of
applications
seen
in
today's
datacenters
many
components
contribute
to
the
overall
power
consumption
and
servers
have
very
narrow
dynamic
range
even
using
voltage
or
frequency
scaling
finally
the
use
of
simple
hybrid
solutions
may
help
in
designing
datacenter
architecture
that
gives
low
latency
good
performance
watt
and
energy
proportionality
in
wide
range
of
workloads
In
the
next
section
we
will
explore
the
options
and
related
challenges
involved
in
the
design
of
such
solution
mention
other
dimensions
DVFS
dynamic
CPU
frequency
scaling
what
about
cost
performance
how
many
atom
servers
for
the
cost
of
one
xeon
server
use
The
task
arrivals
are
modeled
using
Pareto
of
several
design
options
To
this
end
we
use
the
SPECpower
benchmark
to
model
task
duration
times
and
power
consumption
Figures
and
to
derive
task
duration
times
and
power
consumption
We
use
simplified
model
for
multi
core
machines
and
for
the
workload
The
amount
of
work
that
can
be
done
in
unit
of
time
depends
on
the
number
of
cores
and
on
their
effective
computing
capacity
Simultaneous
multi
threading
technology
Hyperthreading
improves
the
performance
of
core
allowing
the
parallel
execution
of
two
tasks
When
core
has
single
task
to
execute
all
the
computing
capacity
is
assigned
to
that
task
When
second
task
start
executing
each
task
gets
share
of
capacity
equal
to
where
is
correction
factor
in
the
range
The
consumed
electrical
power
is
linearly
increasing
between
the
minimum
power
needed
to
have
the
machine
up
and
ready
to
execute
tasks
and
the
power
at
full
utilization
The
instantaneous
power
consumption
at
time
is
where
is
the
instanteneous
utilization
defined
as
the
ratio
between
the
sum
of
the
computing
capacity
share
assigned
to
active
tasks
and
the
total
available
computing
capacity
Load
balancing
is
performed
at
every
task
arrival
departure
to
equally
distribute
the
workload
among
the
available
cores
All
the
tasks
running
on
the
same
core
at
the
same
time
have
the
same
amount
of
computing
capacity
assigned
The
workload
to
be
executed
is
modeled
set
of
tasks
each
identified
by
its
arrival
time
and
by
the
required
computing
resources
In
hybrid
architectures
that
involve
migration
the
load
can
be
moved
between
different
processors
During
the
migration
both
machines
are
running
and
no
tasks
are
performed
The
duration
of
the
transfer
depends
on
the
amount
of
memory
in
use
on
the
source
system
at
migration
time
and
on
the
bandwidth
of
the
transmission
link
Furthermore
the
destination
system
will
need
time
to
wake
up
from
the
sleep
state
The
migration
time
is
Another
important
factor
contributing
to
the
total
power
consumption
is
the
power
used
by
each
system
when
in
sleep
state
We
have
also
considered
the
case
in
which
two
different
architectures
can
work
simultaneously
without
the
need
of
complete
state
migration
In
this
scenario
low
power
architecture
takes
care
of
the
incoming
tasks
until
an
overload
state
is
reached
At
this
point
the
high
performance
machine
wakes
up
and
processes
the
additional
tasks
When
it
has
no
more
load
it
goes
back
to
sleep
coordinator
entity
is
needed
that
distribute
the
tasks
and
wake
the
high
performance
machine
when
necessary
For
the
purpose
of
this
paper
we
use
the
low
power
machine
as
coordinator
In
other
words
the
high
performance
system
is
used
as
an
accelerator
for
the
low
performance
one
Using
the
model
described
above
we
have
carried
out
preliminary
analysis
for
possible
architectures
using
both
an
Atom
and
Xeon
system
Table
reports
the
values
measured
with
the
SPECPower
benchmark
suite
used
in
this
analysis
For
simplicity
we
assume
that
all
tasks
can
be
executed
in
time
on
Xeon
core
at
and
that
both
Atom
and
Xeon
have
The
analysis
is
carried
out
for
the
Atom
machine
Xeon
machine
and
three
hybrid
architectures
Two
different
statistical
distributions
for
task
interarrival
times
are
considered
exponential
and
Pareto
with
shape
parameter
Figure
shows
the
average
power
consumption
as
the
load
increases
load
equal
to
represents
the
maximum
amount
of
work
of
single
Xeon
core
running
continuously
at
and
both
involve
migration
between
Atom
and
Xeon
systems
but
with
different
link
speed
and
wake
up
time
represents
the
ideal
case
with
instantaneous
migration
and
while
in
we
account
both
for
the
wake
up
time
and
for
the
memory
migration
time
on
average
for
each
active
process
represents
different
architecture
in
which
the
Atom
system
is
always
running
and
executes
up
to
four
tasks
two
for
each
core
and
the
Xeon
system
wakes
up
when
an
overload
situation
occurs
As
can
be
seen
in
Figure
Hybrid
architectures
allow
to
achieve
better
energy
proportional
behavior
for
both
distributions
of
interarrival
times
Indeed
far
less
power
is
used
when
the
utilization
is
at
low
levels
solution
with
multiple
Atom
systems
would
probably
exhibit
better
performance
per
Watt
However
as
can
be
seen
in
Figure
hybrid
systems
provide
shorter
execution
times
when
the
load
and
consequently
the
use
of
the
Xeon
system
increases
Design
Options
In
the
previous
section
we
have
shown
the
potential
of
hybrid
solutions
Here
we
set
out
to
define
the
design
questions
to
be
addressed
and
the
challenges
involved
in
exploiting
the
full
potential
of
hybrid
datacenters
Our
intent
is
not
to
describe
solutions
but
rather
to
understand
what
research
agenda
around
hybrid
datacenters
could
look
like
At
high
level
we
consider
design
options
at
two
granularities
datacenter
wide
and
system
level
Capacity
Planning
and
Resource
Scheduling
In
we
have
presented
very
simplified
model
of
datacenter
workload
where
each
server
operates
in
isolation
Modern
datacenters
however
support
many
distributed
facilities
the
most
common
being
the
filesystem
that
could
introduce
dependencies
between
the
operations
of
multiple
servers
when
writing
data
replicas
Relying
heavily
on
low
power
servers
for
this
type
of
background
operations
may
lead
to
unacceptably
long
latencies
In
the
design
of
hybrid
datacenter
there
may
be
need
for
fine
grained
control
over
the
scheduling
of
low
power
and
high
performance
resources
Further
given
the
high
initial
capital
investment
in
datacenters
workload
characterization
is
crucial
to
decide
to
what
degree
datacenter
should
be
hybrid
what
should
be
the
ratio
between
expensive
high
performance
systems
and
low
cost
low
power
systems
how
fast
should
the
high
performance
system
be
compared
to
the
low
power
one
Hardware
and
Software
Architecture
One
possible
dimension
useful
for
classifying
and
evaluating
hardware
and
software
designs
is
the
extent
to
which
the
high
performace
and
low
power
plaftorm
share
common
components
Shared
components
have
direct
impact
on
the
complexity
of
the
software
architecture
the
degree
of
changes
required
in
today's
operating
systems
the
overall
cost
of
the
solution
as
well
as
the
form
factor
and
reliability
of
the
hybrid
platform
All
of
them
are
very
important
aspects
for
datacenter
operators
At
one
extreme
one
could
use
two
complete
and
discrete
systems
where
each
component
disk
network
power
supply
DRAM
banks
is
replicated
and
optimized
for
the
platform
where
it
resides
SSD
vs
HDD
This
solutions
is
the
simplest
from
hardware
perspective
as
it
could
be
deployable
in
the
very
short
term
rack
may
contain
different
servers
Atom
and
Xeon
based
connected
using
standard
network
interfaces
Ethernet
It
is
also
the
most
expensive
as
replicated
components
may
be
go
under
utilized
depending
on
the
workload
This
design
option
is
in
the
same
vein
of
several
research
proposals
FAWN
Marlowe
where
dedicated
set
of
low
power
servers
run
those
bound
workloads
for
which
they
exhibit
the
best
performance
watt
From
software
perspective
it
would
require
to
define
resource
allocation
scheme
to
choose
which
server
to
use
for
any
incoming
task
In
addition
for
datacenters
that
run
cloud
computing
services
there
would
be
need
to
find
ways
to
avoid
using
virtualization
as
Atom
servers
do
not
have
enough
horsepower
to
multiplex
through
virtualization
But
there
would
still
be
the
need
for
some
lightweight
facility
to
migrate
between
Atom
based
physical
machine
and
traditional
Xeon
virtual
machines
In
this
context
an
approach
that
we
plan
to
explore
is
operating
system
migration
without
virtualization
Moving
towards
more
integration
one
could
fit
the
low
power
platform
on
single
PCIe
card
and
use
it
akin
to
the
way
graphics
or
crypto
acceleration
boards
are
used
today
There
is
clear
advantage
in
terms
of
form
factor
datacenter
real
estate
and
ease
of
deployment
no
need
to
run
external
cables
Sharing
the
power
supply
would
reduce
the
cost
but
given
that
the
power
supply
would
be
dimensioned
for
the
high
performance
server
it
may
lead
to
energy
waste
the
power
supply
would
frequently
operate
far
from
the
optimal
efficiency
region
On
the
software
side
it
would
require
new
device
drivers
to
make
use
of
the
new
board
that
would
communicate
with
the
main
CPU
via
DMA
plus
all
the
other
virtualization
related
challenges
discussed
above
Finally
integration
at
the
processor
level
is
also
possible
For
example
Intel's
QuickAssist
allows
to
connect
FPGA
based
chips
to
the
processor
front
side
bus
FSB
One
could
extend
this
approach
to
connect
Atom
chips
directly
to
the
Xeon
FSB
This
way
the
two
processors
would
share
all
the
rest
of
the
platform
memory
hub
disks
etc
Going
further
along
this
path
one
can
imagine
placing
Xeon
and
Atom
cores
next
to
each
other
on
the
same
die
Such
heterogeneous
core
architectures
have
been
proposed
in
several
research
projects
as
way
to
improve
power
consumption
The
main
challenge
with
integration
of
Atom
and
Xeon
cores
or
chips
is
that
the
remaining
system
components
would
have
to
be
optimized
for
low
power
operations
not
the
case
today
where
motherboard
chipsets
do
not
implement
power
management
features
In
addition
radical
change
in
the
hardware
architecture
would
require
deep
changes
to
the
operating
systems
to
make
them
aware
of
the
heterogeneous
nature
of
the
hardware
and
implement
efficient
context
switching
and
data
sharing
between
cores
Completely
new
operating
system
designs
have
been
proposed
Barrelfish
to
exploit
the
characteristics
of
heterogeneous
hardware
using
multi
kernel
approach
Need
to
make
pass
Randy's
comments
some
paper
and
pencil
to
quantify
the
alternatives
proposed
in
the
section
potential
ah
ha
moment
in
this
section
something
bit
surprising
about
which
alternative
looks
the
most
promising
Petros's
comments
talk
about
complexity
challenges
don't
make
blending
together
different
servers
too
obvious
More
details
on
resource
provisioning
and
scheduling
decision
tree
write
down
actual
optimizations
Gives
impression
that
the
sw
side
is
simple
but
it
is
not
In
this
section
we
describe
our
hybrid
approach
to
addressing
power
efficient
and
high
performance
datacenters
and
discuss
different
design
options
Rather
than
using
one
class
of
machines
we
use
mixture
of
servers
low
power
low
performance
server
medium
power
medium
performance
server
and
high
power
high
performance
server
to
achieve
energy
proportionality
while
guaranteeing
performance
service
level
agreements
SLAs
Low
power
low
performance
servers
Intel
Atom
server
consume
low
power
have
good
energy
proportionality
but
cannot
meet
the
performance
of
intensive
workloads
but
high
power
high
performance
servers
Intel
Xeon
server
can
meet
high
performance
requirements
but
consumes
high
power
and
is
not
energy
proportional
There
are
classes
of
servers
that
lie
in
between
Designing
hybrid
datacenter
requires
solving
resource
provisioning
and
scheduling
problems
and
the
architecture
offers
various
hardware
and
software
architecture
options
Given
the
fixed
total
cost
for
the
servers
we
would
like
to
minimize
the
power
cost
while
guaranteeing
performance
SLAs
by
choosing
how
many
servers
from
each
class
to
buy
There
is
also
challenges
on
how
to
schedule
workload
among
the
classes
of
servers
to
reduce
power
consumption
while
guaranteeing
SLAs
Given
workload
we
choose
which
server
type
to
use
When
the
workload
uses
all
subcomponents
intensively
and
tight
performance
requirements
web
transactions
we
allocate
the
workload
to
high
performance
servers
When
the
workload
can
be
easily
parallelizable
and
has
modest
resource
requirements
we
assign
the
workload
to
low
power
servers
Workloads
can
be
misplaced
or
change
over
time
To
handle
these
dynamic
changes
we
rely
on
migration
facilities
between
different
server
types
In
the
following
we
discuss
the
design
spectrum
of
hybrid
datacenter
architecture
we
plan
to
explore
each
design
option
is
presented
based
on
what
is
shared
between
different
classes
of
processors
For
ease
of
understanding
we
use
two
classes
of
servers
For
convenience
we
state
Atom
as
low
power
CPU
and
Xeon
as
high
performance
CPU
Atom
and
Xeon
servers
In
the
simplest
case
we
can
have
Atom
servers
and
Xeon
servers
For
example
each
rack
can
have
both
Atom
and
Xeon
servers
They
communicate
through
typical
network
technologies
such
as
Ethernet
This
does
not
require
any
hardware
modification
but
requires
planning
on
how
many
Atom
and
Xeon
servers
to
put
in
the
datacenter
In
the
software
architecture
we
need
an
allocator
that
decides
what
server
types
to
use
based
on
workloads
The
other
interesting
change
we
need
is
removing
virtualization
in
Atom
servers
since
they
do
not
have
resources
enough
to
multiplex
through
virtualization
However
for
migration
Atom
servers
need
some
lightweight
facility
to
migrate
between
Atom
based
physical
machine
and
virtual
machine
running
in
Xeon
server
that
uses
traditional
VMM
such
as
VMware
and
Xen
We
plan
to
explore
operating
system
migration
without
virtualization
Design
options
in
the
middle
We
can
tie
Atom
and
Xeon
chips
more
tightly
Either
Atom
or
Xeon
chip
can
be
part
of
PCI
card
thus
Atom
and
Xeon
communicating
through
PCI
within
physical
machine
For
example
Xeon
chips
can
be
used
for
computation
requiring
high
performance
while
in
normal
scenarios
Atom
CPUs
are
used
this
usage
is
similar
to
accelerator
cards
such
as
graphics
or
crytography
Furthermore
we
can
design
motherboard
that
hosts
both
Atom
and
Xeon
processors
These
designs
require
OS
changes
in
particular
device
drivers
since
Atom
and
Xeon
communicate
through
DMA
Another
option
is
to
use
Intel's
QuickAssist
that
allows
FSB
attached
FPGA
hardware
modules
We
can
extend
this
to
plugin
Atom
cores
This
allows
Atom
and
Xeon
cores
to
talk
through
Quick
Path
Interconnect
QPI
and
they
share
disk
and
SSD
All
three
options
require
hardware
and
software
changes
Heterogenous
cores
Atom
and
Xeon
cores
In
the
other
end
of
the
design
spectrum
we
can
use
hardware
with
Atom
and
Xeon
cores
in
chip
Several
projects
explore
heterogenous
cores
to
improve
power
consumption
This
design
option
shares
memory
and
disk
among
Atom
and
Xeon
cores
and
migration
between
Atom
and
Xeon
cores
are
efficient
This
hardware
architecture
requires
changes
in
OS
The
OS
needs
to
adapt
to
this
heterogeneity
and
to
provide
efficient
context
switching
between
cores
Another
option
is
to
use
new
OS
such
as
Barrelfish
designed
from
scratch
to
embrace
heterogenous
cores
using
multi
kernel
approach
Related
Work
and
Conclusion
We
have
shown
how
hybrid
datacenters
have
the
potential
to
provide
energy
efficient
operations
without
sacrificing
the
performance
levels
that
today's
datacenter
provide
There
exists
wide
spectrum
of
possible
solutions
some
reachable
in
the
short
term
discrete
solutions
others
that
require
large
investments
heterogeneous
cores
They
all
come
with
different
set
of
trade
offs
and
design
challenges
and
further
work
is
required
to
carefully
evaluate
the
pros
and
cons
of
each
solution
The
research
community
is
very
active
in
this
area
FAWN
is
an
example
of
cluster
architecture
that
consists
of
large
number
of
slow
low
power
embedded
devices
AMD
Geode
coupled
with
flash
storage
The
system
is
efficient
in
terms
of
queries
per
joule
for
particular
seek
bound
and
throughput
bound
applications
Lim
et
al
evaluated
an
alternative
server
architecture
design
built
using
embedded
components
and
showed
improvement
in
performance
per
dollar
Hamilton
made
similar
argument
using
embedded
or
client
side
components
To
our
knowledge
our
approach
is
the
first
to
argue
for
the
case
for
hybrid
approaches
and
to
present
different
design
options
of
hybrid
datacenter
architecture
We
believe
that
the
hybrid
datacenter
architecture
enables
new
power
efficient
infrastructure
for
diverse
workloads
and
offers
interesting
opportunities
for
designing
future
green
computing
infrastructure
Currently
we
are
exploring
different
hybrid
datacenter
design
and
implementation
options
abbrv
A passive network monitoring service for PlanetLab Europe
Luca Niccolini  , Giuseppe Iannaccone  , Angelica Lo Duca
University of Pisa,  Quantavis s.r.l.

Introduction
Live information on network behavior plays a fundamental role in network testbeds both for management purposes and for distributed applications
debugging. During the demonstration we introduce the new PlanetLab Europe (PLE) packettracking infrastructure [1] and show how users
can easily and safely inspect their network experiments using a simple web interface. PlanetLab Europe sites can be augmented with network monitoring hardware used both for passive
and active monitoring. Here we focus on passive
monitoring by means of the CoMo [2] opensource
platform provided by Intel research.
The monitoring service is available to all PLE
users and the number of monitored sites is growing. The only requirements for CoMo monitoring
are a standard Linux machine with at least two
NICs and a network switch that supports port
mirroring. A proxy component has been developed that coordinates access to network resources
and measurement boxes acting as a single secure
access point to the monitoring service. The proxy
oers both a command-line and a web-based secure interface.  1 illustrates the packettracking service architecture.

 1: PLE Packet-tracking architecture
formation can immediately gather results using
CoMo predened modules. These modules collect metrics such as the number of active ows,
the most used port numbers, addresses and protocols by inspecting only packet headers, thus no
user sensitive data are shown. The user clicks on
the measurement box marker over the map and
selects the module to query and the time interval
from a pop-up balloon.
CoMo stores all the measurement data in persistent memory thus it is possible to search and visualize past trac. Results can be presented both
in textual or graphical formats. Textual format is
better suited for post processing with user-dened
scripts. Graphical visualization allows researchers
to immediately preview network behavior before
deeply inspecting it.
Researchers that want to analyze the packet
ow generated by their experiments need to develop their own ad-hoc monitoring application.
We show how a simple CoMo module is imple-

Demo description
For the purpose of this demonstration we show
only the web interface and its main functionalities. When the user logs into the proxy, using its PLE credentials, the measurement boxes
are shown over a world map (see  2). Researchers that are only interested in aggregate in1

 2: CoMo boxes world map

 3: CoMo boxes query form

mented through specic APIs and how it can be
pushed to all the monitoring points in the network
using the proxy web interface. Our proxy also exposes functionalities for reservation and release of
network resources on PLE nodes.
Through a web form the user species each PLE
node, the slice on which the experiment will run
and the port number used by the application. In
this way CoMo is automatically congured to restrict the visibility of the user module only to a
specic network ow. This allows the system to
distinguish between trac generated from dierent users and to ensure privacy.
It is now possible for the user to deploy its application onto PLE nodes and to start it. This
process can be performed using standard PlanetLab tools like CoDeploy [3] or pssh [4]. A full
demonstration of this procedure is beyond the
scope of this demo. CoMo will capture and keep
track of every network packet generated by the
application at any node. The user can query all
the interested nodes together through the query
page of the proxy web interface in which the form
depicted in  3 is displayed.
After the form is submitted, results are shown
in the desired output format and can be downloaded for further oine processing.
In this demonstration we show how MSNP [5],
an instant messaging protocol, can be inspected
in depth using a simple custom module. If a user
name is known then we can nd users location
in the network as well as the destination of her
messages.

Conclusion
The packet-tracking service allows the secure extraction of relevant information about network
behavior from PLE nodes. CoMo allows network
trac inspection with packet resolution while our
proxy provides a single secure access point for
the service and integration of the monitoring architecture within the PlanetLab Europe Internet
testbed.

